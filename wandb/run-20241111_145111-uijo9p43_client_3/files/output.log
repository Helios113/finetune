/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 1380.16it/s]
 11%|█         | 11/100 [00:01<00:08, 10.69it/s]
{'loss': 1.3585, 'grad_norm': 46.12991714477539, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 2.5791, 'grad_norm': 51.43019485473633, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 0.7819, 'grad_norm': 36.95121383666992, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.301, 'grad_norm': 34.34577941894531, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 0.7218, 'grad_norm': 16.65986442565918, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 0.5967, 'grad_norm': 35.74498748779297, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 0.4846, 'grad_norm': 48.919761657714844, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 1.7844, 'grad_norm': 27.063629150390625, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 0.7816, 'grad_norm': 56.76502227783203, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.6917, 'grad_norm': 96.90756225585938, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 0.5319, 'grad_norm': 24.775829315185547, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 0.5629, 'grad_norm': 25.053192138671875, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 0.5699, 'grad_norm': 13.143967628479004, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 0.5686, 'grad_norm': 30.288766860961914, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 1.9072, 'grad_norm': 25.073476791381836, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:06, 10.17it/s]
{'loss': 0.6774, 'grad_norm': 16.802833557128906, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.3046, 'grad_norm': 73.08155822753906, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 1.7639, 'grad_norm': 31.610490798950195, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 0.3388, 'grad_norm': 99.01786041259766, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 0.8416, 'grad_norm': 19.47462272644043, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 0.6123, 'grad_norm': 17.759761810302734, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 0.6847, 'grad_norm': 15.81535530090332, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 0.3823, 'grad_norm': 37.688289642333984, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.7634, 'grad_norm': 56.481319427490234, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 0.4772, 'grad_norm': 18.188232421875, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 0.5997, 'grad_norm': 20.88690948486328, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 1.9158, 'grad_norm': 24.893421173095703, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 0.9333, 'grad_norm': 67.95936584472656, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 0.636, 'grad_norm': 22.96004867553711, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.18, 'grad_norm': 29.54072380065918, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.5719, 'grad_norm': 23.854726791381836, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 0.4749, 'grad_norm': 17.284509658813477, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.3967, 'grad_norm': 19.138744354248047, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 0.8483, 'grad_norm': 54.32939147949219, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.3979, 'grad_norm': 14.45959758758545, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}

 50%|█████     | 50/100 [00:04<00:04, 10.04it/s]
{'loss': 0.4343, 'grad_norm': 30.091514587402344, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 0.7616, 'grad_norm': 37.690303802490234, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 1.2164, 'grad_norm': 52.4290771484375, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 1.4641, 'grad_norm': 31.311365127563477, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.343, 'grad_norm': 45.14677429199219, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.4471, 'grad_norm': 28.418193817138672, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 1.0272, 'grad_norm': 44.54452133178711, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 0.3416, 'grad_norm': 21.48219871520996, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 0.6006, 'grad_norm': 21.64790916442871, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 0.6591, 'grad_norm': 22.398778915405273, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 0.2958, 'grad_norm': 27.118717193603516, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.3933, 'grad_norm': 24.392030715942383, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 0.5752, 'grad_norm': 25.919382095336914, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 1.8289800882339478, 'eval_model_preparation_time': 0.0022, 'eval_runtime': 0.021, 'eval_samples_per_second': 95.335, 'eval_steps_per_second': 47.667, 'epoch': 5.0}
{'loss': 0.9382, 'grad_norm': 26.31365203857422, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 0.3628, 'grad_norm': 26.229188919067383, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 0.475, 'grad_norm': 43.78374099731445, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 0.6422, 'grad_norm': 27.267623901367188, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
 50%|█████     | 50/100 [00:04<00:04, 10.04it/s/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 71%|███████   | 71/100 [00:07<00:02,  9.98it/s]
{'loss': 1.6443, 'grad_norm': 56.930931091308594, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 0.3073, 'grad_norm': 16.371444702148438, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 1.4862, 'grad_norm': 27.54849624633789, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 0.5189, 'grad_norm': 22.51335906982422, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.3577, 'grad_norm': 21.028486251831055, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 0.2641, 'grad_norm': 36.094722747802734, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 0.3956, 'grad_norm': 72.62077331542969, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 0.3563, 'grad_norm': 68.13904571533203, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.9571, 'grad_norm': 62.93601989746094, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.3186, 'grad_norm': 55.34410095214844, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 0.3398, 'grad_norm': 87.50684356689453, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 0.6975, 'grad_norm': 27.86623191833496, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 0.7801, 'grad_norm': 19.003591537475586, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 1.3416, 'grad_norm': 41.65227508544922, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 1.134, 'grad_norm': 35.92295455932617, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.0559, 'grad_norm': 88.71652221679688, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 1.6598, 'grad_norm': 21.51609992980957, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 0.492, 'grad_norm': 36.79022979736328, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 0.6729, 'grad_norm': 36.98995590209961, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 0.313, 'grad_norm': 13.621970176696777, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}

 92%|█████████▏| 92/100 [00:09<00:00, 10.01it/s]
{'loss': 1.0301, 'grad_norm': 63.08761978149414, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 0.2954, 'grad_norm': 15.625483512878418, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 0.428, 'grad_norm': 47.343746185302734, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.1426, 'grad_norm': 35.08501052856445, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 0.9257, 'grad_norm': 43.66463088989258, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 0.76, 'grad_norm': 47.16089630126953, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 0.6145, 'grad_norm': 35.26673889160156, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.6138, 'grad_norm': 58.778167724609375, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 0.4438, 'grad_norm': 23.586135864257812, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 0.7326, 'grad_norm': 18.546218872070312, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 0.3695, 'grad_norm': 22.751819610595703, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 1.2158, 'grad_norm': 27.132408142089844, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 0.7111, 'grad_norm': 35.98320388793945, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.2347, 'grad_norm': 138.02066040039062, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 2.364, 'grad_norm': 64.22046661376953, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.3832, 'grad_norm': 35.66446304321289, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.201, 'grad_norm': 44.87965393066406, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 0.3957, 'grad_norm': 51.2873420715332, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 0.8874, 'grad_norm': 22.415407180786133, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
100%|██████████| 100/100 [00:10<00:00, 10.14it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.68it/s]
{'loss': 0.8099, 'grad_norm': 34.9455451965332, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 0.3051, 'grad_norm': 33.07448959350586, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 0.9561, 'grad_norm': 29.76377296447754, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 0.2972, 'grad_norm': 25.538917541503906, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 1.9414713382720947, 'eval_model_preparation_time': 0.0022, 'eval_runtime': 0.0207, 'eval_samples_per_second': 96.537, 'eval_steps_per_second': 48.269, 'epoch': 10.0}
{'train_runtime': 10.3245, 'train_samples_per_second': 38.743, 'train_steps_per_second': 9.686, 'train_loss': 0.8460526283085347, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 9