/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 1239.45it/s]
 12%|█▏        | 12/100 [00:01<00:09,  9.78it/s]
{'loss': 2.2765, 'grad_norm': 22.75983238220215, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.5622, 'grad_norm': 71.57006072998047, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.8019, 'grad_norm': 33.16315460205078, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 2.0594, 'grad_norm': 29.95242691040039, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 1.7872, 'grad_norm': 26.682491302490234, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 1.6066, 'grad_norm': 20.93459129333496, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 2.2999, 'grad_norm': 35.428436279296875, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 0.8222, 'grad_norm': 27.616451263427734, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 0.6288, 'grad_norm': 15.55970573425293, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 1.5412, 'grad_norm': 284.02642822265625, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.3607, 'grad_norm': 19.615182876586914, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.694, 'grad_norm': 26.392396926879883, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.1371, 'grad_norm': 21.132020950317383, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 1.0514, 'grad_norm': 20.8228702545166, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 1.0871, 'grad_norm': 46.240089416503906, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 33%|███▎      | 33/100 [00:03<00:06, 10.13it/s]
{'loss': 2.421, 'grad_norm': 60.29677963256836, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 2.093, 'grad_norm': 48.799415588378906, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 0.7123, 'grad_norm': 13.118021965026855, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 1.1782, 'grad_norm': 34.66754913330078, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 0.6169, 'grad_norm': 37.34782791137695, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 0.5889, 'grad_norm': 16.10710906982422, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.6135, 'grad_norm': 64.5255126953125, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.7491, 'grad_norm': 35.15171813964844, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.4679, 'grad_norm': 25.51292610168457, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 1.7771, 'grad_norm': 27.185016632080078, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 2.0194, 'grad_norm': 31.075992584228516, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 2.5827, 'grad_norm': 25.89678382873535, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 0.5103, 'grad_norm': 8.88263988494873, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 1.2516, 'grad_norm': 23.494834899902344, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 2.2679, 'grad_norm': 21.269411087036133, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.2232, 'grad_norm': 17.17103385925293, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.8168, 'grad_norm': 30.950660705566406, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.5539, 'grad_norm': 17.873310089111328, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.8936, 'grad_norm': 47.02702331542969, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 2.1354, 'grad_norm': 25.205810546875, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:04, 10.02it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:04, 10.02it/s]
{'loss': 0.5889, 'grad_norm': 13.802624702453613, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.3744, 'grad_norm': 36.524227142333984, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 1.6016, 'grad_norm': 28.876632690429688, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 2.1821, 'grad_norm': 23.568754196166992, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.5499, 'grad_norm': 33.40507507324219, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 0.6097, 'grad_norm': 17.808494567871094, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 1.7972, 'grad_norm': 42.13127899169922, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 1.3504, 'grad_norm': 43.846126556396484, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 1.5651, 'grad_norm': 24.02192497253418, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.0986, 'grad_norm': 18.871780395507812, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 2.5148, 'grad_norm': 31.07295799255371, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.9249, 'grad_norm': 23.654443740844727, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 0.628, 'grad_norm': 15.648308753967285, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.7272425293922424, 'eval_model_preparation_time': 0.0022, 'eval_runtime': 0.0206, 'eval_samples_per_second': 97.214, 'eval_steps_per_second': 48.607, 'epoch': 5.0}
{'loss': 2.5809, 'grad_norm': 21.21266746520996, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.9439, 'grad_norm': 27.495010375976562, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 0.536, 'grad_norm': 13.936141014099121, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.4227, 'grad_norm': 26.652441024780273, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}

 71%|███████   | 71/100 [00:07<00:02,  9.83it/s]
{'loss': 1.3351, 'grad_norm': 20.40382957458496, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 2.0298, 'grad_norm': 24.95396614074707, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 0.8903, 'grad_norm': 35.82472610473633, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 0.8702, 'grad_norm': 20.116579055786133, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.6995, 'grad_norm': 31.72384262084961, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 2.0145, 'grad_norm': 21.281095504760742, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 1.0702, 'grad_norm': 19.436193466186523, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 1.3398, 'grad_norm': 23.250717163085938, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.4953, 'grad_norm': 42.26079559326172, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.4059, 'grad_norm': 19.043352127075195, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 0.6066, 'grad_norm': 13.114466667175293, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 0.8198, 'grad_norm': 22.817977905273438, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.6243, 'grad_norm': 21.542102813720703, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 2.1603, 'grad_norm': 35.2905387878418, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 3.1843, 'grad_norm': 35.90217971801758, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.9134, 'grad_norm': 34.31637191772461, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 1.4334, 'grad_norm': 23.910297393798828, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 1.6903, 'grad_norm': 27.356151580810547, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 0.8176, 'grad_norm': 124.2549819946289, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}

 91%|█████████ | 91/100 [00:09<00:00,  9.81it/s]
{'loss': 2.1513, 'grad_norm': 42.8765754699707, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.4916, 'grad_norm': 23.4490909576416, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 0.6735, 'grad_norm': 38.61602020263672, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 1.2516, 'grad_norm': 17.076461791992188, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 0.545, 'grad_norm': 27.561508178710938, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.2571, 'grad_norm': 20.896318435668945, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 0.5811, 'grad_norm': 15.1172513961792, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.9587, 'grad_norm': 41.91829299926758, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.1194, 'grad_norm': 28.353275299072266, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 0.7758, 'grad_norm': 12.567880630493164, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 2.1216, 'grad_norm': 42.248863220214844, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 0.4542, 'grad_norm': 16.84295082092285, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 0.6025, 'grad_norm': 16.664339065551758, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.3974, 'grad_norm': 36.15542221069336, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 2.5901, 'grad_norm': 30.819740295410156, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.4807, 'grad_norm': 65.93490600585938, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 1.4786, 'grad_norm': 42.063621520996094, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 1.7584, 'grad_norm': 19.270158767700195, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.5067, 'grad_norm': 49.878822326660156, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
100%|██████████| 100/100 [00:10<00:00,  9.98it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.61it/s]
{'loss': 1.8562, 'grad_norm': 30.411457061767578, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 1.5264, 'grad_norm': 25.359209060668945, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 0.4803, 'grad_norm': 14.913039207458496, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 1.8134, 'grad_norm': 20.873149871826172, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 0.5361, 'grad_norm': 28.618938446044922, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.7291111350059509, 'eval_model_preparation_time': 0.0022, 'eval_runtime': 0.0225, 'eval_samples_per_second': 88.831, 'eval_steps_per_second': 44.416, 'epoch': 10.0}
{'train_runtime': 10.4096, 'train_samples_per_second': 38.426, 'train_steps_per_second': 9.607, 'train_loss': 1.473042846918106, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 5