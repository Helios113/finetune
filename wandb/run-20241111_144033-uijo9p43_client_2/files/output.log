/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 958.48it/s]
 15%|█▌        | 15/100 [00:01<00:07, 10.69it/s]
{'loss': 1.567, 'grad_norm': 24.74751091003418, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.6749, 'grad_norm': 26.60685920715332, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 1.7731, 'grad_norm': 33.488441467285156, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 2.5732, 'grad_norm': 34.689632415771484, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.3109, 'grad_norm': 20.179248809814453, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 1.7094, 'grad_norm': 31.36797523498535, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 0.6352, 'grad_norm': 13.034996032714844, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 1.6466, 'grad_norm': 18.02272605895996, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 1.493, 'grad_norm': 24.254615783691406, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.682, 'grad_norm': 30.886110305786133, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 0.4537, 'grad_norm': 12.665802001953125, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 2.3926, 'grad_norm': 22.683210372924805, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.1605, 'grad_norm': 26.112974166870117, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.0738, 'grad_norm': 28.289657592773438, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 0.6798, 'grad_norm': 24.08978843688965, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}
{'loss': 0.5151, 'grad_norm': 12.309289932250977, 'learning_rate': 4.690766700109659e-05, 'epoch': 1.6}
{'loss': 1.2715, 'grad_norm': 27.07193374633789, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}

 35%|███▌      | 35/100 [00:03<00:06,  9.97it/s]
{'loss': 2.5676, 'grad_norm': 33.871826171875, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 2.0507, 'grad_norm': 46.93721008300781, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 1.8154, 'grad_norm': 20.840044021606445, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 2.0081, 'grad_norm': 31.15281867980957, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 1.7747, 'grad_norm': 62.949012756347656, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.3575, 'grad_norm': 53.3113899230957, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 0.4453, 'grad_norm': 14.58980941772461, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 1.3253, 'grad_norm': 27.583492279052734, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 1.864, 'grad_norm': 26.711645126342773, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 0.7394, 'grad_norm': 59.91537094116211, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 1.5662, 'grad_norm': 42.964603424072266, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 2.6658, 'grad_norm': 32.46402359008789, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.9065, 'grad_norm': 21.476436614990234, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 2.0095, 'grad_norm': 21.16335105895996, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.7763, 'grad_norm': 23.7490291595459, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 1.3001, 'grad_norm': 18.261430740356445, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 0.7527, 'grad_norm': 21.57346534729004, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.8468, 'grad_norm': 20.417144775390625, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:05,  9.75it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 53%|█████▎    | 53/100 [00:05<00:06,  7.73it/s]
{'loss': 1.7085, 'grad_norm': 25.005847930908203, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.3762, 'grad_norm': 47.43947982788086, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.5435, 'grad_norm': 26.656835556030273, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 0.9578, 'grad_norm': 28.774028778076172, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.5444, 'grad_norm': 16.9615421295166, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.9116, 'grad_norm': 31.03237533569336, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 1.6805, 'grad_norm': 22.13433074951172, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 2.605, 'grad_norm': 20.572233200073242, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 1.5507, 'grad_norm': 25.74270248413086, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.0787, 'grad_norm': 28.556493759155273, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 0.376, 'grad_norm': 25.454408645629883, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 1.409, 'grad_norm': 24.444822311401367, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 1.4289, 'grad_norm': 33.47966384887695, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 2.2898740768432617, 'eval_model_preparation_time': 0.0008, 'eval_runtime': 0.0202, 'eval_samples_per_second': 98.984, 'eval_steps_per_second': 49.492, 'epoch': 5.0}
{'loss': 1.5841, 'grad_norm': 23.307863235473633, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.0868, 'grad_norm': 37.82600021362305, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 2.103, 'grad_norm': 18.721248626708984, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 0.5921, 'grad_norm': 26.2996826171875, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}

 73%|███████▎  | 73/100 [00:07<00:02,  9.94it/s]
{'loss': 0.6443, 'grad_norm': 23.182024002075195, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 1.6476, 'grad_norm': 28.906845092773438, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 1.1953, 'grad_norm': 26.18125343322754, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 0.6522, 'grad_norm': 13.151309967041016, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 1.7806, 'grad_norm': 44.71500778198242, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 0.4918, 'grad_norm': 14.115324974060059, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 1.6634, 'grad_norm': 21.516555786132812, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 2.1298, 'grad_norm': 25.627573013305664, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 0.7357, 'grad_norm': 21.33086585998535, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.8334, 'grad_norm': 24.83158302307129, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.2839, 'grad_norm': 24.172290802001953, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 1.4695, 'grad_norm': 23.27114486694336, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.6069, 'grad_norm': 38.378353118896484, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 1.4818, 'grad_norm': 21.074024200439453, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 0.7643, 'grad_norm': 28.20053482055664, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.0608, 'grad_norm': 20.266122817993164, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 0.6108, 'grad_norm': 16.630565643310547, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 1.7991, 'grad_norm': 33.63239669799805, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.9751, 'grad_norm': 17.498994827270508, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 0.4544, 'grad_norm': 15.851751327514648, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}

 94%|█████████▍| 94/100 [00:09<00:00, 10.38it/s]
{'loss': 1.7973, 'grad_norm': 26.618221282958984, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 1.531, 'grad_norm': 33.61601257324219, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 2.0193, 'grad_norm': 22.44599151611328, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 0.3826, 'grad_norm': 43.536712646484375, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 0.7168, 'grad_norm': 20.74737548828125, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 0.7805, 'grad_norm': 18.817697525024414, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 0.3494, 'grad_norm': 23.483678817749023, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 0.3514, 'grad_norm': 16.85256004333496, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 2.2784, 'grad_norm': 19.461854934692383, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.9408, 'grad_norm': 26.897741317749023, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 2.4497, 'grad_norm': 39.9953498840332, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 1.1293, 'grad_norm': 22.38774871826172, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 1.2949, 'grad_norm': 29.4470272064209, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.219, 'grad_norm': 18.034379959106445, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.4266, 'grad_norm': 18.582868576049805, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 1.1623, 'grad_norm': 26.47564125061035, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.48, 'grad_norm': 19.921428680419922, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.6981, 'grad_norm': 20.567243576049805, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 1.6605, 'grad_norm': 22.34656524658203, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
100%|██████████| 100/100 [00:10<00:00, 10.03it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.75it/s]
{'loss': 1.4026, 'grad_norm': 36.70170974731445, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 0.4374, 'grad_norm': 14.167802810668945, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 1.8261, 'grad_norm': 21.645389556884766, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 1.5328, 'grad_norm': 38.872955322265625, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 2.34318470954895, 'eval_model_preparation_time': 0.0008, 'eval_runtime': 0.0238, 'eval_samples_per_second': 83.991, 'eval_steps_per_second': 41.996, 'epoch': 10.0}
{'train_runtime': 10.2527, 'train_samples_per_second': 39.014, 'train_steps_per_second': 9.754, 'train_loss': 1.3638134966790676, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 6