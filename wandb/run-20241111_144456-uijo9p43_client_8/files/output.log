/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 928.56it/s]
 12%|█▏        | 12/100 [00:01<00:08, 10.27it/s]
{'loss': 1.5048, 'grad_norm': 59.402156829833984, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.7324, 'grad_norm': 24.092424392700195, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 1.9606, 'grad_norm': 36.99800491333008, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.4986, 'grad_norm': 30.295028686523438, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.6388, 'grad_norm': 36.402286529541016, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 1.298, 'grad_norm': 32.95903396606445, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.2492, 'grad_norm': 79.35193634033203, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 1.602, 'grad_norm': 22.17767906188965, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 0.4917, 'grad_norm': 37.28401565551758, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.7945, 'grad_norm': 16.125642776489258, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.848, 'grad_norm': 46.990596771240234, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.5946, 'grad_norm': 31.221744537353516, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 1.6135, 'grad_norm': 26.7385196685791, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.1889, 'grad_norm': 20.6168270111084, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 0.5772, 'grad_norm': 16.091650009155273, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:06,  9.73it/s]
{'loss': 1.0066, 'grad_norm': 32.71531295776367, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.7499, 'grad_norm': 35.153560638427734, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 1.6149, 'grad_norm': 41.318115234375, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 0.7018, 'grad_norm': 76.58721160888672, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 0.4618, 'grad_norm': 28.569459915161133, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 1.8, 'grad_norm': 51.74008560180664, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 0.9883, 'grad_norm': 45.32313919067383, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.6838, 'grad_norm': 29.822038650512695, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 0.6672, 'grad_norm': 41.57929229736328, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 0.7773, 'grad_norm': 25.362720489501953, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 2.1703, 'grad_norm': 29.761276245117188, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 2.1633, 'grad_norm': 30.818889617919922, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 0.7449, 'grad_norm': 24.982484817504883, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 1.9989, 'grad_norm': 46.50782775878906, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.8519, 'grad_norm': 34.362247467041016, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.5208, 'grad_norm': 37.99785232543945, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 0.6346, 'grad_norm': 46.899593353271484, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 1.4759, 'grad_norm': 39.43499755859375, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 0.831, 'grad_norm': 26.85506248474121, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 1.3588, 'grad_norm': 44.21718978881836, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:05<00:05,  9.89it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:06,  7.35it/s]
{'loss': 0.5335, 'grad_norm': 29.225238800048828, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.4022, 'grad_norm': 22.931640625, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 1.2024, 'grad_norm': 62.709163665771484, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 2.3952, 'grad_norm': 157.67791748046875, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.522, 'grad_norm': 46.48928451538086, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 2.2543, 'grad_norm': 39.2855110168457, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 1.2118, 'grad_norm': 47.41261672973633, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 1.2409, 'grad_norm': 23.410005569458008, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 0.7416, 'grad_norm': 38.81914520263672, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 0.5286, 'grad_norm': 39.36591339111328, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 0.9763, 'grad_norm': 30.987363815307617, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.8012, 'grad_norm': 22.060380935668945, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 1.508, 'grad_norm': 24.050168991088867, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 2.030604839324951, 'eval_model_preparation_time': 0.0017, 'eval_runtime': 0.022, 'eval_samples_per_second': 90.844, 'eval_steps_per_second': 45.422, 'epoch': 5.0}
{'loss': 2.2117, 'grad_norm': 241.24661254882812, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.4646, 'grad_norm': 42.859588623046875, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 0.8943, 'grad_norm': 37.29921340942383, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 0.5605, 'grad_norm': 15.039948463439941, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}

 75%|███████▌  | 75/100 [00:07<00:02, 12.19it/s]
{'loss': 1.6366, 'grad_norm': 37.49337387084961, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 1.3218, 'grad_norm': 27.011606216430664, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 0.5324, 'grad_norm': 33.36658477783203, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 1.16, 'grad_norm': 24.844032287597656, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.7081, 'grad_norm': 42.30990219116211, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.1501, 'grad_norm': 22.120723724365234, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 0.8875, 'grad_norm': 36.37092590332031, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 1.4423, 'grad_norm': 32.92072677612305, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.2402, 'grad_norm': 18.752286911010742, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.3964, 'grad_norm': 39.5495719909668, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 0.4054, 'grad_norm': 18.179224014282227, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 1.6494, 'grad_norm': 66.90217590332031, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.2072, 'grad_norm': 30.572702407836914, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 1.4595, 'grad_norm': 39.47023391723633, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 1.4837, 'grad_norm': 130.9907684326172, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 0.934, 'grad_norm': 48.786556243896484, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 0.4835, 'grad_norm': 26.18561363220215, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 1.286, 'grad_norm': 48.67205810546875, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.2468, 'grad_norm': 32.92817306518555, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 1.7434, 'grad_norm': 26.204818725585938, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 0.7283, 'grad_norm': 38.35219192504883, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.3211, 'grad_norm': 53.49504852294922, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 0.4052, 'grad_norm': 127.12786865234375, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}

 95%|█████████▌| 95/100 [00:09<00:00,  9.93it/s]
{'loss': 1.8129, 'grad_norm': 42.78586196899414, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.2204, 'grad_norm': 48.9599609375, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.7717, 'grad_norm': 23.063074111938477, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 0.5858, 'grad_norm': 16.147872924804688, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.4678, 'grad_norm': 19.995283126831055, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.0845, 'grad_norm': 55.2823600769043, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.4975, 'grad_norm': 26.65190315246582, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 0.7938, 'grad_norm': 91.2481918334961, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 1.1462, 'grad_norm': 72.44966888427734, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 0.927, 'grad_norm': 35.00779342651367, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.7584, 'grad_norm': 25.95351219177246, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.7648, 'grad_norm': 29.89628791809082, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.3754, 'grad_norm': 14.999306678771973, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.6901, 'grad_norm': 60.44859313964844, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 0.689, 'grad_norm': 39.16304397583008, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 0.5167, 'grad_norm': 25.007186889648438, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.0054, 'grad_norm': 25.984708786010742, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 0.9042, 'grad_norm': 24.46892547607422, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 2.1083, 'grad_norm': 52.72752380371094, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
100%|██████████| 100/100 [00:09<00:00, 10.28it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.96it/s]
{'loss': 0.7532, 'grad_norm': 37.4728889465332, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 2.098372220993042, 'eval_model_preparation_time': 0.0017, 'eval_runtime': 0.0195, 'eval_samples_per_second': 102.618, 'eval_steps_per_second': 51.309, 'epoch': 10.0}
{'train_runtime': 10.0355, 'train_samples_per_second': 39.858, 'train_steps_per_second': 9.965, 'train_loss': 1.2478539130091668, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 2