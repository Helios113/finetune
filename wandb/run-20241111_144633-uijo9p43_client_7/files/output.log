/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 871.45it/s]
 12%|█▏        | 12/100 [00:01<00:08, 10.33it/s]
{'loss': 0.8168, 'grad_norm': 25.690746307373047, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.9166, 'grad_norm': 55.21672821044922, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.5631, 'grad_norm': 65.8282241821289, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.8387, 'grad_norm': 69.35794067382812, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.5736, 'grad_norm': 34.16087341308594, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 0.545, 'grad_norm': 12.969972610473633, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.9915, 'grad_norm': 58.63410568237305, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.3731, 'grad_norm': 36.19948196411133, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 1.2982, 'grad_norm': 92.02059936523438, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.4362, 'grad_norm': 74.31475830078125, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.7086, 'grad_norm': 24.706008911132812, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 0.4016, 'grad_norm': 10.913409233093262, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.2222, 'grad_norm': 36.94472122192383, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 1.9858, 'grad_norm': 43.79877853393555, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 1.7498, 'grad_norm': 20.863922119140625, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}
{'loss': 1.0558, 'grad_norm': 27.628395080566406, 'learning_rate': 4.690766700109659e-05, 'epoch': 1.6}

 33%|███▎      | 33/100 [00:03<00:06, 10.15it/s]
{'loss': 1.2023, 'grad_norm': 22.067453384399414, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.6894, 'grad_norm': 50.54352951049805, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 1.0472, 'grad_norm': 95.44910430908203, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 1.2627, 'grad_norm': 36.49909591674805, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 2.2963, 'grad_norm': 42.94889831542969, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.1999, 'grad_norm': 62.68903732299805, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.7902, 'grad_norm': 29.031679153442383, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.3572, 'grad_norm': 27.842775344848633, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 1.668, 'grad_norm': 29.18960189819336, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 1.1023, 'grad_norm': 48.2110481262207, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 1.1918, 'grad_norm': 21.948923110961914, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 0.8728, 'grad_norm': 52.674259185791016, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 0.6163, 'grad_norm': 50.04896545410156, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 0.9578, 'grad_norm': 22.952686309814453, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.5272, 'grad_norm': 46.83803939819336, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 0.871, 'grad_norm': 30.473154067993164, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.2835, 'grad_norm': 13.240839004516602, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.6678, 'grad_norm': 28.89363670349121, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.644, 'grad_norm': 28.99945831298828, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:05,  9.84it/s/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:07,  6.67it/s]
{'loss': 2.6593, 'grad_norm': 31.72816276550293, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.2366, 'grad_norm': 32.450592041015625, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.379, 'grad_norm': 119.41548919677734, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 1.7352, 'grad_norm': 20.39668846130371, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.394, 'grad_norm': 28.708641052246094, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 2.8733, 'grad_norm': 32.11778259277344, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 0.7445, 'grad_norm': 24.18312644958496, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 1.2736, 'grad_norm': 30.671724319458008, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 1.6493, 'grad_norm': 31.35154914855957, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 0.3016, 'grad_norm': 13.19976806640625, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 0.8898, 'grad_norm': 40.6501350402832, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.5772, 'grad_norm': 36.43528366088867, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.4566, 'grad_norm': 27.23219871520996, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.6732251048088074, 'eval_model_preparation_time': 0.003, 'eval_runtime': 0.0204, 'eval_samples_per_second': 97.854, 'eval_steps_per_second': 48.927, 'epoch': 5.0}
{'loss': 2.36, 'grad_norm': 32.81826400756836, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 0.8349, 'grad_norm': 15.238186836242676, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 1.5809, 'grad_norm': 111.53764343261719, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.5975, 'grad_norm': 19.580106735229492, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 1.2119, 'grad_norm': 43.52109146118164, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}

 72%|███████▏  | 72/100 [00:07<00:02, 10.10it/s]
{'loss': 0.2975, 'grad_norm': 14.74236011505127, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 2.1444, 'grad_norm': 40.589637756347656, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 0.6322, 'grad_norm': 37.123294830322266, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 2.0813, 'grad_norm': 71.10675811767578, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 0.8399, 'grad_norm': 17.114946365356445, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 0.3822, 'grad_norm': 19.58909797668457, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 1.4936, 'grad_norm': 69.53013610839844, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.888, 'grad_norm': 21.248903274536133, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.2607, 'grad_norm': 19.349515914916992, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.0457, 'grad_norm': 22.209318161010742, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 1.5613, 'grad_norm': 33.56605911254883, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.3533, 'grad_norm': 64.08638000488281, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 1.4949, 'grad_norm': 82.84378814697266, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.4682, 'grad_norm': 45.972530364990234, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.5591, 'grad_norm': 24.972875595092773, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 2.4684, 'grad_norm': 24.311880111694336, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 0.7989, 'grad_norm': 22.491127014160156, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.3573, 'grad_norm': 48.76621627807617, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 1.4559, 'grad_norm': 19.75360679626465, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}

 92%|█████████▏| 92/100 [00:09<00:00, 10.09it/s]
{'loss': 1.0303, 'grad_norm': 24.56595230102539, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 0.3974, 'grad_norm': 18.72469139099121, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 0.7131, 'grad_norm': 26.322647094726562, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.5763, 'grad_norm': 63.410770416259766, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.1983, 'grad_norm': 18.27498435974121, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.3636, 'grad_norm': 19.796890258789062, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.2436, 'grad_norm': 22.16265869140625, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.3273, 'grad_norm': 50.5925178527832, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.2708, 'grad_norm': 32.72071075439453, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.455, 'grad_norm': 64.22945404052734, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 0.9699, 'grad_norm': 67.18474578857422, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 1.2734, 'grad_norm': 40.4710578918457, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 1.8541, 'grad_norm': 31.072311401367188, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.7882, 'grad_norm': 38.31081771850586, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.9206, 'grad_norm': 42.95985794067383, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 1.0898, 'grad_norm': 15.739123344421387, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.4934, 'grad_norm': 29.40030860900879, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.4304, 'grad_norm': 28.923608779907227, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 0.4097, 'grad_norm': 21.25841522216797, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
100%|██████████| 100/100 [00:10<00:00, 10.13it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.78it/s]
{'loss': 2.0485, 'grad_norm': 30.914653778076172, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.238, 'grad_norm': 20.162609100341797, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 1.7938, 'grad_norm': 20.18471908569336, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 0.9898, 'grad_norm': 52.55011749267578, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.7176132202148438, 'eval_model_preparation_time': 0.003, 'eval_runtime': 0.0223, 'eval_samples_per_second': 89.846, 'eval_steps_per_second': 44.923, 'epoch': 10.0}
{'train_runtime': 10.2231, 'train_samples_per_second': 39.127, 'train_steps_per_second': 9.782, 'train_loss': 1.400304805636406, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 2