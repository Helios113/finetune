/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 920.21it/s]
 12%|█▏        | 12/100 [00:01<00:08,  9.82it/s]
{'loss': 0.384, 'grad_norm': 38.8756103515625, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.5875, 'grad_norm': 171.6320037841797, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 0.8964, 'grad_norm': 64.04517364501953, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.2227, 'grad_norm': 32.19115447998047, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 1.7025, 'grad_norm': 63.556846618652344, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 1.8801, 'grad_norm': 40.00536346435547, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.372, 'grad_norm': 47.84485626220703, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.1338, 'grad_norm': 78.46420288085938, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 2.6653, 'grad_norm': 34.304046630859375, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 2.261, 'grad_norm': 46.05744934082031, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 0.4204, 'grad_norm': 52.6089973449707, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.6009, 'grad_norm': 26.593685150146484, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 0.7823, 'grad_norm': 60.12493133544922, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.7733, 'grad_norm': 34.29000473022461, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 1.1957, 'grad_norm': 93.39076232910156, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 33%|███▎      | 33/100 [00:03<00:06, 10.16it/s]
{'loss': 0.6824, 'grad_norm': 43.738136291503906, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.6041, 'grad_norm': 27.46628189086914, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.3264, 'grad_norm': 42.89963150024414, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 1.7963, 'grad_norm': 42.956138610839844, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 0.6292, 'grad_norm': 54.99407958984375, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 1.7947, 'grad_norm': 26.247386932373047, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.8288, 'grad_norm': 46.64255905151367, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.2317, 'grad_norm': 34.572593688964844, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 0.3395, 'grad_norm': 19.866161346435547, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 0.5946, 'grad_norm': 28.50623321533203, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 1.2619, 'grad_norm': 53.47926330566406, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 1.0663, 'grad_norm': 39.53679275512695, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 1.3692, 'grad_norm': 27.69340705871582, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 2.3441, 'grad_norm': 55.333412170410156, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 2.6205, 'grad_norm': 35.731502532958984, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 2.0331, 'grad_norm': 30.595624923706055, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.8068, 'grad_norm': 38.32326889038086, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.3825, 'grad_norm': 27.937009811401367, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 0.8604, 'grad_norm': 46.651615142822266, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
 50%|█████     | 50/100 [00:04<00:04, 10.61it/s/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 52%|█████▏    | 52/100 [00:05<00:06,  7.75it/s]
{'loss': 0.468, 'grad_norm': 25.96851348876953, 'learning_rate': 3.4928697265869515e-05, 'epoch': 3.7}
{'loss': 2.1926, 'grad_norm': 48.7303581237793, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.1673, 'grad_norm': 54.984500885009766, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.4437, 'grad_norm': 29.45077896118164, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 1.0166, 'grad_norm': 58.06438446044922, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.2042, 'grad_norm': 44.958221435546875, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.0265, 'grad_norm': 24.563692092895508, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 2.1965, 'grad_norm': 76.63985443115234, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 2.5871, 'grad_norm': 71.58160400390625, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 0.4052, 'grad_norm': 136.31105041503906, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 0.4866, 'grad_norm': 35.06424331665039, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 1.8841, 'grad_norm': 107.9518814086914, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 1.6517, 'grad_norm': 90.53367614746094, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 0.8069, 'grad_norm': 56.26689529418945, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.6422845125198364, 'eval_model_preparation_time': 0.0011, 'eval_runtime': 0.0229, 'eval_samples_per_second': 87.256, 'eval_steps_per_second': 43.628, 'epoch': 5.0}
{'loss': 0.6306, 'grad_norm': 43.84450912475586, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.2772, 'grad_norm': 158.1160888671875, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 0.762, 'grad_norm': 39.97405242919922, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.2112, 'grad_norm': 69.1974105834961, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}

 72%|███████▏  | 72/100 [00:07<00:02,  9.93it/s]
{'loss': 0.8944, 'grad_norm': 100.93641662597656, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 1.5344, 'grad_norm': 29.974506378173828, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 1.3551, 'grad_norm': 42.449546813964844, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.0312, 'grad_norm': 41.61874008178711, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 1.623, 'grad_norm': 57.95698165893555, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.9487, 'grad_norm': 120.0824203491211, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 1.6644, 'grad_norm': 118.17237854003906, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 0.2816, 'grad_norm': 65.57027435302734, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.3505, 'grad_norm': 51.61862564086914, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.4603, 'grad_norm': 23.60616683959961, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 0.4254, 'grad_norm': 27.87255096435547, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 2.1934, 'grad_norm': 25.867830276489258, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.5875, 'grad_norm': 33.545066833496094, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 0.9982, 'grad_norm': 25.971820831298828, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 0.7609, 'grad_norm': 39.52593231201172, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 0.6623, 'grad_norm': 25.529617309570312, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 0.869, 'grad_norm': 67.24392700195312, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 2.1471, 'grad_norm': 37.79753112792969, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.7879, 'grad_norm': 71.196533203125, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 0.2779, 'grad_norm': 188.22640991210938, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}

 93%|█████████▎| 93/100 [00:09<00:00,  9.98it/s]
{'loss': 0.4023, 'grad_norm': 20.675111770629883, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 2.801, 'grad_norm': 39.440547943115234, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 0.2188, 'grad_norm': 19.47941780090332, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 1.422, 'grad_norm': 38.840206146240234, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 0.3518, 'grad_norm': 21.717605590820312, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.3523, 'grad_norm': 46.419456481933594, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 0.2742, 'grad_norm': 24.70071029663086, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 0.2177, 'grad_norm': 20.78468894958496, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.4361, 'grad_norm': 29.2457332611084, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.5277, 'grad_norm': 27.381772994995117, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 0.8761, 'grad_norm': 33.05099105834961, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 2.6087, 'grad_norm': 62.99856185913086, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.0656, 'grad_norm': 74.51136016845703, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.5406, 'grad_norm': 56.138362884521484, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.7599, 'grad_norm': 37.73556900024414, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.768, 'grad_norm': 24.648950576782227, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.4607, 'grad_norm': 24.393884658813477, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.8891, 'grad_norm': 74.07898712158203, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 2.4363, 'grad_norm': 29.79552459716797, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
100%|██████████| 100/100 [00:10<00:00,  9.96it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.74it/s]
{'loss': 1.537, 'grad_norm': 40.28843307495117, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.1732, 'grad_norm': 45.3983154296875, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 0.4729, 'grad_norm': 23.100706100463867, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 0.1995, 'grad_norm': 33.434661865234375, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.631655216217041, 'eval_model_preparation_time': 0.0011, 'eval_runtime': 0.0224, 'eval_samples_per_second': 89.234, 'eval_steps_per_second': 44.617, 'epoch': 10.0}
{'train_runtime': 10.2619, 'train_samples_per_second': 38.979, 'train_steps_per_second': 9.745, 'train_loss': 1.278887349963188, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 3