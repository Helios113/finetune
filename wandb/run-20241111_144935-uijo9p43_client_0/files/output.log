/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 1141.00it/s]
 13%|█▎        | 13/100 [00:01<00:07, 11.76it/s]
{'loss': 0.3285, 'grad_norm': 24.32170867919922, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.5357, 'grad_norm': 39.74705505371094, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.473, 'grad_norm': 40.37211608886719, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.5874, 'grad_norm': 34.46098709106445, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.2829, 'grad_norm': 39.259681701660156, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 2.7216, 'grad_norm': 48.03487777709961, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 0.9218, 'grad_norm': 28.829030990600586, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.1083, 'grad_norm': 50.959293365478516, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 2.0735, 'grad_norm': 58.778564453125, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 1.9957, 'grad_norm': 30.59736442565918, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.3885, 'grad_norm': 33.16874313354492, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 0.8344, 'grad_norm': 18.264217376708984, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.5913, 'grad_norm': 24.626665115356445, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.78, 'grad_norm': 28.28229331970215, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.1669, 'grad_norm': 23.746259689331055, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}
{'loss': 0.6765, 'grad_norm': 14.27322006225586, 'learning_rate': 4.690766700109659e-05, 'epoch': 1.6}
{'loss': 1.8826, 'grad_norm': 34.01710510253906, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 0.9078, 'grad_norm': 29.70206642150879, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.3184, 'grad_norm': 24.932453155517578, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}

 40%|████      | 40/100 [00:03<00:05, 10.79it/s]
{'loss': 1.3061, 'grad_norm': 14.889603614807129, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 2.7865, 'grad_norm': 55.93667221069336, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 1.5761, 'grad_norm': 26.71940803527832, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 0.5239, 'grad_norm': 36.17829895019531, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 0.3843, 'grad_norm': 31.826274871826172, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 2.399, 'grad_norm': 45.009761810302734, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 2.4521, 'grad_norm': 128.6005096435547, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 0.8125, 'grad_norm': 19.411508560180664, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 1.6359, 'grad_norm': 27.054719924926758, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 1.6178, 'grad_norm': 82.96279907226562, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 0.6072, 'grad_norm': 22.98041343688965, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.9468, 'grad_norm': 25.489931106567383, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.8324, 'grad_norm': 72.85150909423828, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 1.4037, 'grad_norm': 24.5877685546875, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.0822, 'grad_norm': 25.097461700439453, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 1.6356, 'grad_norm': 27.739229202270508, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
{'loss': 2.0317, 'grad_norm': 84.6476058959961, 'learning_rate': 3.4928697265869515e-05, 'epoch': 3.7}
{'loss': 1.3001, 'grad_norm': 38.986907958984375, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 2.4167, 'grad_norm': 51.2564811706543, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.8461, 'grad_norm': 27.79107093811035, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 0.5529, 'grad_norm': 20.080345153808594, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.6964, 'grad_norm': 28.695621490478516, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.6026, 'grad_norm': 42.99433517456055, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
 50%|█████     | 50/100 [00:04<00:04, 10.30it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 64%|██████▍   | 64/100 [00:05<00:02, 14.68it/s]
{'loss': 2.8211, 'grad_norm': 52.312931060791016, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 2.8832, 'grad_norm': 45.9494743347168, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.706, 'grad_norm': 35.79306411743164, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 0.7323, 'grad_norm': 20.785367965698242, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.7703, 'grad_norm': 22.905654907226562, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.6662, 'grad_norm': 132.57208251953125, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.8769533634185791, 'eval_model_preparation_time': 0.0009, 'eval_runtime': 0.0214, 'eval_samples_per_second': 93.608, 'eval_steps_per_second': 46.804, 'epoch': 5.0}
{'loss': 1.0628, 'grad_norm': 25.545207977294922, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 0.3343, 'grad_norm': 19.859394073486328, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 2.1652, 'grad_norm': 30.545148849487305, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.1534, 'grad_norm': 28.859649658203125, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 2.1389, 'grad_norm': 35.754512786865234, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}
{'loss': 1.3514, 'grad_norm': 44.68100357055664, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 0.8137, 'grad_norm': 57.502750396728516, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 2.4858, 'grad_norm': 30.13266372680664, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.1479, 'grad_norm': 55.74127197265625, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.2182, 'grad_norm': 52.83547592163086, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.4366, 'grad_norm': 28.26585578918457, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 1.9649, 'grad_norm': 63.43413162231445, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 2.2129, 'grad_norm': 34.29240417480469, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 0.3038, 'grad_norm': 12.279047966003418, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.5896, 'grad_norm': 18.05548858642578, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.8014, 'grad_norm': 35.791603088378906, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 2.1215, 'grad_norm': 36.022151947021484, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}

 84%|████████▍ | 84/100 [00:07<00:01, 10.12it/s]
{'loss': 2.0231, 'grad_norm': 27.428558349609375, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 0.5431, 'grad_norm': 33.03562927246094, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.4371, 'grad_norm': 54.86655807495117, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 0.5232, 'grad_norm': 15.496818542480469, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 2.4551, 'grad_norm': 34.73474884033203, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 0.9857, 'grad_norm': 45.99415969848633, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 1.2715, 'grad_norm': 35.9560432434082, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.2404, 'grad_norm': 42.313499450683594, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.4449, 'grad_norm': 20.234806060791016, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 1.3415, 'grad_norm': 24.592618942260742, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 1.397, 'grad_norm': 19.82887077331543, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.3401, 'grad_norm': 81.63409423828125, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.107, 'grad_norm': 36.977474212646484, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.6975, 'grad_norm': 30.967819213867188, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.9996, 'grad_norm': 26.931615829467773, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 0.6114, 'grad_norm': 46.389305114746094, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 0.9046, 'grad_norm': 30.87944221496582, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.6569, 'grad_norm': 24.68675422668457, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 1.8952, 'grad_norm': 29.027637481689453, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
100%|██████████| 100/100 [00:08<00:00, 10.70it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:09<00:00, 11.08it/s]
{'loss': 1.4941, 'grad_norm': 20.488998413085938, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.1378, 'grad_norm': 8.635836601257324, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 0.6731, 'grad_norm': 18.64691925048828, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.4023, 'grad_norm': 13.287893295288086, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.8293, 'grad_norm': 17.106786727905273, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.1799, 'grad_norm': 16.940160751342773, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 1.3735, 'grad_norm': 22.88886833190918, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.343, 'grad_norm': 32.27247619628906, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 2.2873, 'grad_norm': 46.46320343017578, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.0124, 'grad_norm': 44.511104583740234, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 2.2708, 'grad_norm': 59.6522102355957, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 2.5585, 'grad_norm': 41.799503326416016, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.8791055679321289, 'eval_model_preparation_time': 0.0009, 'eval_runtime': 0.0215, 'eval_samples_per_second': 93.198, 'eval_steps_per_second': 46.599, 'epoch': 10.0}
{'train_runtime': 9.0221, 'train_samples_per_second': 44.335, 'train_steps_per_second': 11.084, 'train_loss': 1.4857923896610736, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 6