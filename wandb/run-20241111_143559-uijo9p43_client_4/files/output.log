/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
Map: 100%|██████████| 38/38 [00:00<00:00, 1083.04 examples/s]
Map: 100%|██████████| 2/2 [00:00<00:00, 100.78 examples/s]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 976.56it/s]
 11%|█         | 11/100 [00:01<00:08, 10.26it/s]
{'loss': 2.488, 'grad_norm': 23.527482986450195, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.3068, 'grad_norm': 41.42413330078125, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 3.0148, 'grad_norm': 23.23076057434082, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 2.9021, 'grad_norm': 23.69877052307129, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 1.9979, 'grad_norm': 22.953611373901367, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 1.2112, 'grad_norm': 34.32939529418945, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 2.5323, 'grad_norm': 51.05748748779297, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.2449, 'grad_norm': 18.8118896484375, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 2.5825, 'grad_norm': 14.39502239227295, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.661, 'grad_norm': 26.26984214782715, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 2.477, 'grad_norm': 18.037418365478516, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 2.3006, 'grad_norm': 22.0639591217041, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 1.9241, 'grad_norm': 22.804576873779297, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 1.9193, 'grad_norm': 22.406949996948242, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.2835, 'grad_norm': 14.03076171875, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 31%|███       | 31/100 [00:03<00:06, 10.01it/s]
{'loss': 1.8892, 'grad_norm': 17.02810287475586, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.0571, 'grad_norm': 24.276058197021484, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.1279, 'grad_norm': 19.76127815246582, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 3.0804, 'grad_norm': 39.313209533691406, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 1.4072, 'grad_norm': 19.639780044555664, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 1.086, 'grad_norm': 13.84527587890625, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 1.6055, 'grad_norm': 19.479093551635742, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.6534, 'grad_norm': 22.58656883239746, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 2.2488, 'grad_norm': 19.894311904907227, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 3.631, 'grad_norm': 28.258281707763672, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 1.531, 'grad_norm': 23.828310012817383, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 2.1304, 'grad_norm': 85.89530181884766, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 2.8549, 'grad_norm': 29.662708282470703, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 0.9054, 'grad_norm': 31.885149002075195, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.2568, 'grad_norm': 15.068547248840332, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.9015, 'grad_norm': 20.80211639404297, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 0.526, 'grad_norm': 11.611261367797852, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 2.9044, 'grad_norm': 22.57501220703125, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 2.1454, 'grad_norm': 22.081378936767578, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}

 50%|█████     | 50/100 [00:05<00:05,  9.81it/s]
{'loss': 2.2243, 'grad_norm': 50.59068298339844, 'learning_rate': 3.4928697265869515e-05, 'epoch': 3.7}
{'loss': 1.3661, 'grad_norm': 17.7304744720459, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 2.1268, 'grad_norm': 12.566033363342285, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 2.8142, 'grad_norm': 44.87255859375, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 0.7681, 'grad_norm': 14.787099838256836, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 2.5273, 'grad_norm': 20.900306701660156, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 2.0879, 'grad_norm': 16.30074119567871, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 2.4877, 'grad_norm': 46.23737716674805, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 1.2974, 'grad_norm': 29.746116638183594, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 2.8342, 'grad_norm': 21.92535972595215, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 2.1106, 'grad_norm': 30.849361419677734, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 1.2315, 'grad_norm': 20.82271385192871, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 1.7638, 'grad_norm': 13.15385913848877, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 1.5973, 'grad_norm': 25.10539436340332, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.7544978260993958, 'eval_model_preparation_time': 0.0016, 'eval_runtime': 0.0215, 'eval_samples_per_second': 92.952, 'eval_steps_per_second': 46.476, 'epoch': 5.0}
{'loss': 1.9671, 'grad_norm': 20.801774978637695, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.2964, 'grad_norm': 34.69813537597656, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 1.8496, 'grad_norm': 17.98679542541504, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
 50%|█████     | 50/100 [00:05<00:05,  9.81it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 70%|███████   | 70/100 [00:07<00:03,  9.77it/s]
{'loss': 2.1111, 'grad_norm': 29.58766746520996, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}
{'loss': 3.4956, 'grad_norm': 19.373186111450195, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 1.0405, 'grad_norm': 42.421024322509766, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 1.0874, 'grad_norm': 25.146574020385742, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.138, 'grad_norm': 25.26047134399414, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.6747, 'grad_norm': 27.798404693603516, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.3654, 'grad_norm': 27.354656219482422, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 1.8627, 'grad_norm': 22.835020065307617, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 2.7584, 'grad_norm': 46.70335006713867, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 0.915, 'grad_norm': 21.538646697998047, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.8338, 'grad_norm': 15.04932975769043, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.225, 'grad_norm': 36.03738784790039, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 1.3678, 'grad_norm': 16.164213180541992, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 2.0632, 'grad_norm': 32.346641540527344, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 2.4752, 'grad_norm': 16.028491973876953, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.4601, 'grad_norm': 26.438688278198242, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.7785, 'grad_norm': 19.06390380859375, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 1.4011, 'grad_norm': 17.993423461914062, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 1.6976, 'grad_norm': 24.01995849609375, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 0.9057, 'grad_norm': 13.727923393249512, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}

 92%|█████████▏| 92/100 [00:09<00:00, 11.66it/s]
{'loss': 3.2624, 'grad_norm': 19.327234268188477, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.9048, 'grad_norm': 26.485139846801758, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 1.163, 'grad_norm': 18.55307960510254, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 1.1905, 'grad_norm': 22.8953914642334, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.8744, 'grad_norm': 42.63725662231445, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 2.6404, 'grad_norm': 22.024072647094727, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 2.024, 'grad_norm': 16.710716247558594, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.179, 'grad_norm': 54.13484191894531, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.1633, 'grad_norm': 29.509553909301758, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.2202, 'grad_norm': 20.350584030151367, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.6312, 'grad_norm': 34.88624954223633, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 0.7791, 'grad_norm': 11.797286033630371, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 2.8533, 'grad_norm': 18.37755012512207, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.1708, 'grad_norm': 29.2623291015625, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 2.179, 'grad_norm': 19.312498092651367, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 2.3372, 'grad_norm': 16.483489990234375, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 2.1136, 'grad_norm': 34.63093185424805, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 1.4444, 'grad_norm': 19.43416404724121, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.0836, 'grad_norm': 18.974964141845703, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 1.5584, 'grad_norm': 28.659278869628906, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 2.5878, 'grad_norm': 20.10646629333496, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
100%|██████████| 100/100 [00:10<00:00, 12.02it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.81it/s]
{'loss': 2.0561, 'grad_norm': 21.588441848754883, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 1.2175, 'grad_norm': 20.820404052734375, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 2.5129, 'grad_norm': 19.19660758972168, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.73451167345047, 'eval_model_preparation_time': 0.0016, 'eval_runtime': 0.0215, 'eval_samples_per_second': 92.895, 'eval_steps_per_second': 46.448, 'epoch': 10.0}
{'train_runtime': 10.1957, 'train_samples_per_second': 39.232, 'train_steps_per_second': 9.808, 'train_loss': 1.89923585832119, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 0