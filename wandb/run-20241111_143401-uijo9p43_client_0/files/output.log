/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
Map: 100%|██████████| 38/38 [00:00<00:00, 1482.39 examples/s]
Map: 100%|██████████| 2/2 [00:00<00:00, 130.44 examples/s]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 972.03it/s]
 11%|█         | 11/100 [00:01<00:08, 10.19it/s]
{'loss': 1.6018, 'grad_norm': 18.730854034423828, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 3.2062, 'grad_norm': 24.441186904907227, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 3.6512, 'grad_norm': 17.494386672973633, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 2.6288, 'grad_norm': 17.58317756652832, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 3.572, 'grad_norm': 20.984277725219727, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 3.3781, 'grad_norm': 20.350862503051758, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.946, 'grad_norm': 26.533981323242188, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.7208, 'grad_norm': 21.177032470703125, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 3.0499, 'grad_norm': 21.518083572387695, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 3.3241, 'grad_norm': 27.555580139160156, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 3.0461, 'grad_norm': 45.90863037109375, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 2.0229, 'grad_norm': 13.646103858947754, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 3.4239, 'grad_norm': 13.150897979736328, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 3.4888, 'grad_norm': 16.549968719482422, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.752, 'grad_norm': 13.244318962097168, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:06, 10.35it/s]
{'loss': 3.4778, 'grad_norm': 15.463170051574707, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 2.2223, 'grad_norm': 16.077369689941406, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 3.3793, 'grad_norm': 18.971336364746094, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 1.752, 'grad_norm': 32.24655532836914, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 2.1352, 'grad_norm': 20.432405471801758, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 3.7476, 'grad_norm': 19.6640625, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.8186, 'grad_norm': 16.756223678588867, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 2.3741, 'grad_norm': 58.21601104736328, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.3637, 'grad_norm': 17.96649169921875, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 3.1014, 'grad_norm': 15.685944557189941, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 3.0528, 'grad_norm': 18.430313110351562, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 1.2873, 'grad_norm': 11.422056198120117, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 2.8596, 'grad_norm': 69.54200744628906, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 3.8923, 'grad_norm': 31.872568130493164, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 2.0229, 'grad_norm': 71.78005981445312, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 3.2083, 'grad_norm': 43.89047622680664, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 2.7065, 'grad_norm': 18.256317138671875, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 2.5333, 'grad_norm': 18.427391052246094, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 2.7288, 'grad_norm': 15.9934720993042, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
 50%|█████     | 50/100 [00:05<00:04, 10.24it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:04, 10.24it/s]
{'loss': 2.768, 'grad_norm': 13.708558082580566, 'learning_rate': 3.4928697265869515e-05, 'epoch': 3.7}
{'loss': 2.3554, 'grad_norm': 26.893674850463867, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 3.3325, 'grad_norm': 21.201440811157227, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 1.4383, 'grad_norm': 28.10471534729004, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 2.4778, 'grad_norm': 25.6070556640625, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.3784, 'grad_norm': 18.319934844970703, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 2.7126, 'grad_norm': 15.52337646484375, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 1.7257, 'grad_norm': 41.73196029663086, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 3.7585, 'grad_norm': 50.24683380126953, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 3.9059, 'grad_norm': 23.097774505615234, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 2.5703, 'grad_norm': 15.378783226013184, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 1.3499, 'grad_norm': 26.113544464111328, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 2.1969, 'grad_norm': 11.77593994140625, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.7601, 'grad_norm': 16.429794311523438, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 1.3994183540344238, 'eval_model_preparation_time': 0.0016, 'eval_runtime': 0.024, 'eval_samples_per_second': 83.223, 'eval_steps_per_second': 41.611, 'epoch': 5.0}
{'loss': 2.3964, 'grad_norm': 10.798873901367188, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.8157, 'grad_norm': 16.238813400268555, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 3.2021, 'grad_norm': 15.289369583129883, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.9896, 'grad_norm': 12.54570484161377, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}

 73%|███████▎  | 73/100 [00:07<00:02, 10.48it/s]
{'loss': 1.7514, 'grad_norm': 20.23904037475586, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 1.9714, 'grad_norm': 13.644692420959473, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 3.787, 'grad_norm': 16.113183975219727, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.5185, 'grad_norm': 15.552947998046875, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 1.8365, 'grad_norm': 31.582504272460938, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 2.111, 'grad_norm': 20.143131256103516, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 2.8916, 'grad_norm': 13.43431282043457, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 3.4242, 'grad_norm': 19.84210777282715, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 0.7974, 'grad_norm': 14.453800201416016, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.8747, 'grad_norm': 16.74859619140625, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 2.9595, 'grad_norm': 10.109253883361816, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 3.0692, 'grad_norm': 19.82645606994629, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.9421, 'grad_norm': 15.351428031921387, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 2.4611, 'grad_norm': 13.28817081451416, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.1824, 'grad_norm': 19.31006622314453, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 2.8477, 'grad_norm': 22.610595703125, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 1.073, 'grad_norm': 10.633208274841309, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 2.9668, 'grad_norm': 13.582239151000977, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 2.6704, 'grad_norm': 16.020980834960938, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 2.1917, 'grad_norm': 18.250513076782227, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.6677, 'grad_norm': 22.361005783081055, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}

 93%|█████████▎| 93/100 [00:09<00:00,  9.61it/s]
{'loss': 2.2685, 'grad_norm': 24.617172241210938, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 2.6663, 'grad_norm': 20.03156852722168, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 3.0012, 'grad_norm': 22.74448013305664, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.9808, 'grad_norm': 21.718517303466797, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 2.378, 'grad_norm': 30.521318435668945, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 2.848, 'grad_norm': 15.690189361572266, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.8888, 'grad_norm': 13.289338111877441, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 2.4867, 'grad_norm': 14.59206485748291, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 2.2754, 'grad_norm': 20.282344818115234, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 3.1126, 'grad_norm': 15.788145065307617, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 2.4363, 'grad_norm': 19.607322692871094, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.6946, 'grad_norm': 14.298912048339844, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 1.1158, 'grad_norm': 14.953092575073242, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.7435, 'grad_norm': 11.536548614501953, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.7654, 'grad_norm': 9.395907402038574, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 2.0508, 'grad_norm': 14.674660682678223, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 2.0222, 'grad_norm': 13.708515167236328, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 2.2782, 'grad_norm': 12.38428783416748, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 2.1378, 'grad_norm': 20.08473777770996, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
100%|██████████| 100/100 [00:10<00:00, 10.01it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.77it/s]
{'loss': 2.7285, 'grad_norm': 21.235231399536133, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 2.8356, 'grad_norm': 12.536458015441895, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 3.5197, 'grad_norm': 19.436614990234375, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 1.38829505443573, 'eval_model_preparation_time': 0.0016, 'eval_runtime': 0.0201, 'eval_samples_per_second': 99.529, 'eval_steps_per_second': 49.765, 'epoch': 10.0}
{'train_runtime': 10.2362, 'train_samples_per_second': 39.077, 'train_steps_per_second': 9.769, 'train_loss': 2.5182234156131744, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 9