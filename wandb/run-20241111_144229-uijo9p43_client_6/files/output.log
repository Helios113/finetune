/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 922.43it/s]
 11%|█         | 11/100 [00:01<00:09,  9.80it/s]
{'loss': 1.2985, 'grad_norm': 42.24284362792969, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 2.3882, 'grad_norm': 30.09758758544922, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 1.9478, 'grad_norm': 40.10146713256836, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.7384, 'grad_norm': 41.916595458984375, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.9692, 'grad_norm': 29.568012237548828, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 0.8424, 'grad_norm': 68.58405303955078, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 2.0602, 'grad_norm': 36.28508758544922, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.3012, 'grad_norm': 32.527191162109375, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 1.0655, 'grad_norm': 49.44816207885742, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.5249, 'grad_norm': 81.14825439453125, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.0712, 'grad_norm': 54.720462799072266, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.9748, 'grad_norm': 21.900327682495117, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 1.4582, 'grad_norm': 54.450653076171875, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 1.8057, 'grad_norm': 72.34820556640625, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.6368, 'grad_norm': 26.058504104614258, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:05, 11.37it/s]
{'loss': 1.9627, 'grad_norm': 43.197792053222656, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.8962, 'grad_norm': 26.371131896972656, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 1.5846, 'grad_norm': 20.362075805664062, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 0.9405, 'grad_norm': 45.2540397644043, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 2.3282, 'grad_norm': 33.04189682006836, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 2.6719, 'grad_norm': 32.99938201904297, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.4918, 'grad_norm': 25.024324417114258, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.0053, 'grad_norm': 48.07944107055664, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 2.1086, 'grad_norm': 46.913997650146484, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 1.85, 'grad_norm': 35.41041564941406, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 0.3921, 'grad_norm': 15.627153396606445, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 0.7034, 'grad_norm': 13.494709968566895, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 0.5732, 'grad_norm': 29.66712760925293, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 1.938, 'grad_norm': 33.53575897216797, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.755, 'grad_norm': 33.83879852294922, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 0.7471, 'grad_norm': 19.35030174255371, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.4636, 'grad_norm': 27.625469207763672, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.986, 'grad_norm': 49.55551528930664, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.8456, 'grad_norm': 37.63401412963867, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.6685, 'grad_norm': 99.18807220458984, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:04, 10.46it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:04, 10.46it/s]
{'loss': 1.6723, 'grad_norm': 34.995513916015625, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.7069, 'grad_norm': 22.679126739501953, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.521, 'grad_norm': 24.835371017456055, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 1.4417, 'grad_norm': 31.036121368408203, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.7164, 'grad_norm': 44.5107536315918, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 2.1614, 'grad_norm': 46.00648880004883, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 1.0435, 'grad_norm': 30.07908821105957, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 0.5736, 'grad_norm': 33.750831604003906, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 2.3765, 'grad_norm': 30.201330184936523, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.5758, 'grad_norm': 22.49242401123047, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 1.2927, 'grad_norm': 26.953418731689453, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 1.2834, 'grad_norm': 27.121572494506836, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 1.9867, 'grad_norm': 60.57771301269531, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 3.055713415145874, 'eval_model_preparation_time': 0.0013, 'eval_runtime': 0.0251, 'eval_samples_per_second': 79.554, 'eval_steps_per_second': 39.777, 'epoch': 5.0}
{'loss': 3.2587, 'grad_norm': 29.551475524902344, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.1717, 'grad_norm': 29.61244773864746, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 1.6508, 'grad_norm': 24.112951278686523, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.9941, 'grad_norm': 24.579029083251953, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 0.5749, 'grad_norm': 24.406415939331055, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}

 74%|███████▍  | 74/100 [00:07<00:02, 10.75it/s]
{'loss': 1.4011, 'grad_norm': 32.283695220947266, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 1.8881, 'grad_norm': 28.6097469329834, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 0.6731, 'grad_norm': 15.244881629943848, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 1.2119, 'grad_norm': 35.93944549560547, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.1135, 'grad_norm': 35.59672164916992, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 0.4145, 'grad_norm': 21.289344787597656, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 0.5377, 'grad_norm': 22.690658569335938, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.8026, 'grad_norm': 24.780115127563477, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.5144, 'grad_norm': 24.697872161865234, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 0.9395, 'grad_norm': 29.359424591064453, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 2.1788, 'grad_norm': 36.7099609375, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.36, 'grad_norm': 31.32227897644043, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 2.2062, 'grad_norm': 23.170068740844727, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.7382, 'grad_norm': 81.19041442871094, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 2.3593, 'grad_norm': 42.986942291259766, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 2.0899, 'grad_norm': 29.94997215270996, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 1.5782, 'grad_norm': 48.50759506225586, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 2.0268, 'grad_norm': 35.639862060546875, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 2.0939, 'grad_norm': 29.653125762939453, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.3845, 'grad_norm': 53.03373718261719, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 0.5248, 'grad_norm': 32.20644760131836, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 0.4267, 'grad_norm': 20.609548568725586, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}

 96%|█████████▌| 96/100 [00:09<00:00, 10.50it/s]
{'loss': 1.1641, 'grad_norm': 29.43255043029785, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.0018, 'grad_norm': 39.246742248535156, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.8232, 'grad_norm': 24.530881881713867, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.8095, 'grad_norm': 30.724241256713867, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.4675, 'grad_norm': 25.42452621459961, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.8627, 'grad_norm': 30.29685401916504, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.0595, 'grad_norm': 20.307226181030273, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 1.4633, 'grad_norm': 28.52520179748535, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 0.8584, 'grad_norm': 24.251285552978516, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.0311, 'grad_norm': 87.39154815673828, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.7888, 'grad_norm': 55.681949615478516, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 2.0233, 'grad_norm': 33.09246063232422, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.627, 'grad_norm': 36.23557662963867, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.7064, 'grad_norm': 45.230796813964844, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.4647, 'grad_norm': 22.558582305908203, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 0.3537, 'grad_norm': 24.53936004638672, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.5368, 'grad_norm': 36.331695556640625, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 2.4473, 'grad_norm': 29.95856285095215, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.6473, 'grad_norm': 23.495349884033203, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 1.1576, 'grad_norm': 24.288488388061523, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 2.1536, 'grad_norm': 51.07065200805664, 'learning_rate': 0.0, 'epoch': 10.0}
100%|██████████| 100/100 [00:09<00:00, 10.22it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:09<00:00, 10.07it/s]
{'train_runtime': 9.9249, 'train_samples_per_second': 40.303, 'train_steps_per_second': 10.076, 'train_loss': 1.5153734594583512, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 1