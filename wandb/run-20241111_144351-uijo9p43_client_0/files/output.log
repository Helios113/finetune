/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 971.58it/s]
 12%|█▏        | 12/100 [00:01<00:08, 10.08it/s]
{'loss': 0.6582, 'grad_norm': 31.899620056152344, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.6858, 'grad_norm': 53.09352111816406, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.5233, 'grad_norm': 47.49217224121094, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.8756, 'grad_norm': 29.710834503173828, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.6893, 'grad_norm': 57.587013244628906, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 2.7719, 'grad_norm': 33.29706573486328, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.0146, 'grad_norm': 63.175235748291016, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.045, 'grad_norm': 32.6241455078125, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 2.4677, 'grad_norm': 38.99020004272461, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 2.0458, 'grad_norm': 35.855220794677734, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.8567, 'grad_norm': 35.37934494018555, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.0663, 'grad_norm': 21.8812255859375, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.6485, 'grad_norm': 26.540822982788086, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.8683, 'grad_norm': 48.036598205566406, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.0897, 'grad_norm': 20.969552993774414, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 42%|████▏     | 42/100 [00:03<00:03, 16.01it/s]
{'loss': 2.1654, 'grad_norm': 26.181949615478516, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.0747, 'grad_norm': 23.909273147583008, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.3898, 'grad_norm': 20.984905242919922, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 0.5185, 'grad_norm': 49.09466552734375, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 1.3844, 'grad_norm': 30.663957595825195, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 3.0221, 'grad_norm': 25.035297393798828, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 1.872, 'grad_norm': 24.42304229736328, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 0.8637, 'grad_norm': 33.56874084472656, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 0.4834, 'grad_norm': 25.605735778808594, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 2.4166, 'grad_norm': 32.94154357910156, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 2.5657, 'grad_norm': 26.6541805267334, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 0.9012, 'grad_norm': 42.828643798828125, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 1.8065, 'grad_norm': 28.881887435913086, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 2.004, 'grad_norm': 33.93242263793945, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 0.8469, 'grad_norm': 65.57357788085938, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 2.053, 'grad_norm': 18.809663772583008, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.8203, 'grad_norm': 29.712411880493164, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 1.6191, 'grad_norm': 34.663753509521484, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.3935, 'grad_norm': 25.793703079223633, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 1.6502, 'grad_norm': 31.921571731567383, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
{'loss': 2.2227, 'grad_norm': 49.01815414428711, 'learning_rate': 3.4928697265869515e-05, 'epoch': 3.7}
{'loss': 1.5396, 'grad_norm': 21.552541732788086, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 2.6182, 'grad_norm': 27.343849182128906, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.9923, 'grad_norm': 25.11118507385254, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 0.9847, 'grad_norm': 31.203384399414062, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.8289, 'grad_norm': 17.640439987182617, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.7099, 'grad_norm': 32.3531379699707, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 0.8383, 'grad_norm': 25.501832962036133, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 2.9687, 'grad_norm': 48.68509292602539, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 3.0559, 'grad_norm': 33.05024337768555, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.7602, 'grad_norm': 27.355060577392578, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
 50%|█████     | 50/100 [00:03<00:02, 16.78it/s/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 64%|██████▍   | 64/100 [00:05<00:03, 10.14it/s]
{'loss': 0.8739, 'grad_norm': 24.68317222595215, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.341, 'grad_norm': 33.50053787231445, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.8414197564125061, 'eval_model_preparation_time': 0.002, 'eval_runtime': 0.0185, 'eval_samples_per_second': 108.215, 'eval_steps_per_second': 54.107, 'epoch': 5.0}
{'loss': 1.4025, 'grad_norm': 33.42024612426758, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 0.6424, 'grad_norm': 29.48604393005371, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 2.2429, 'grad_norm': 21.950428009033203, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.1872, 'grad_norm': 22.91809844970703, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 2.3054, 'grad_norm': 23.966148376464844, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}
{'loss': 1.3331, 'grad_norm': 23.80073356628418, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 0.9682, 'grad_norm': 20.96791648864746, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 2.6278, 'grad_norm': 38.03611373901367, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.0713, 'grad_norm': 45.75372314453125, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.3831, 'grad_norm': 30.68084144592285, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.2608, 'grad_norm': 23.5814151763916, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 2.0508, 'grad_norm': 21.745912551879883, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 2.4281, 'grad_norm': 24.96705436706543, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 0.3826, 'grad_norm': 17.35906219482422, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.778, 'grad_norm': 27.071857452392578, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.9861, 'grad_norm': 71.2119369506836, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 2.3507, 'grad_norm': 46.13113021850586, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}

 84%|████████▍ | 84/100 [00:07<00:01,  9.90it/s]
{'loss': 1.9523, 'grad_norm': 25.42887306213379, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 0.8543, 'grad_norm': 34.92253875732422, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.5288, 'grad_norm': 23.23503875732422, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 0.6572, 'grad_norm': 30.363439559936523, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 2.3262, 'grad_norm': 25.963239669799805, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.1664, 'grad_norm': 19.601612091064453, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 1.6656, 'grad_norm': 45.99315643310547, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.2885, 'grad_norm': 28.118494033813477, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.6302, 'grad_norm': 29.15115737915039, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 1.4484, 'grad_norm': 25.847888946533203, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 1.6215, 'grad_norm': 25.717172622680664, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.4502, 'grad_norm': 43.06580352783203, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.2499, 'grad_norm': 26.15206527709961, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.7227, 'grad_norm': 33.77688980102539, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 2.1834, 'grad_norm': 34.92399978637695, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 0.9308, 'grad_norm': 26.276172637939453, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.0892, 'grad_norm': 23.391836166381836, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.7508, 'grad_norm': 19.379745483398438, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 1.9183, 'grad_norm': 16.731487274169922, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
100%|██████████| 100/100 [00:08<00:00, 10.17it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:09<00:00, 11.04it/s]
{'loss': 1.6159, 'grad_norm': 35.05885314941406, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.164, 'grad_norm': 15.30743408203125, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 0.7975, 'grad_norm': 18.805511474609375, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.4825, 'grad_norm': 21.488933563232422, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.8773, 'grad_norm': 20.211896896362305, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.335, 'grad_norm': 22.361499786376953, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 1.4415, 'grad_norm': 32.212093353271484, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.4866, 'grad_norm': 22.461448669433594, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 2.5587, 'grad_norm': 19.62417221069336, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.3965, 'grad_norm': 37.285423278808594, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 2.1484, 'grad_norm': 22.089845657348633, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 2.516, 'grad_norm': 53.85636901855469, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.8149941563606262, 'eval_model_preparation_time': 0.002, 'eval_runtime': 0.0199, 'eval_samples_per_second': 100.7, 'eval_steps_per_second': 50.35, 'epoch': 10.0}
{'train_runtime': 9.0564, 'train_samples_per_second': 44.168, 'train_steps_per_second': 11.042, 'train_loss': 1.6278972280025483, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 2