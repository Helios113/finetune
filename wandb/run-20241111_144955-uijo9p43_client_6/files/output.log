/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 959.58it/s]
 12%|█▏        | 12/100 [00:01<00:08,  9.98it/s]
{'loss': 0.5985, 'grad_norm': 40.073280334472656, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 2.1156, 'grad_norm': 30.936168670654297, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 1.6252, 'grad_norm': 24.93301010131836, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.5912, 'grad_norm': 42.84798812866211, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.6682, 'grad_norm': 24.21424674987793, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 0.7445, 'grad_norm': 25.753440856933594, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.5694, 'grad_norm': 38.42787551879883, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.1195, 'grad_norm': 20.86932373046875, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 0.9087, 'grad_norm': 29.952234268188477, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.3544, 'grad_norm': 27.710071563720703, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 0.7473, 'grad_norm': 23.03768539428711, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.5044, 'grad_norm': 33.45037078857422, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 1.2161, 'grad_norm': 49.407901763916016, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 1.4218, 'grad_norm': 31.938457489013672, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.3115, 'grad_norm': 24.456106185913086, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:06, 10.15it/s]
{'loss': 1.5484, 'grad_norm': 25.639184951782227, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.6908, 'grad_norm': 28.03331184387207, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 1.3846, 'grad_norm': 23.50511360168457, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 0.5215, 'grad_norm': 53.900672912597656, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 2.005, 'grad_norm': 24.755416870117188, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 2.4231, 'grad_norm': 35.71580123901367, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.268, 'grad_norm': 27.630279541015625, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 0.5636, 'grad_norm': 33.01282501220703, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.5379, 'grad_norm': 44.20134735107422, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 1.5355, 'grad_norm': 33.24859619140625, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 0.2486, 'grad_norm': 16.528291702270508, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 0.6661, 'grad_norm': 24.677114486694336, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 0.5349, 'grad_norm': 26.669221878051758, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 1.6087, 'grad_norm': 36.00600814819336, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.6391, 'grad_norm': 33.24072265625, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 0.344, 'grad_norm': 15.456230163574219, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.2287, 'grad_norm': 41.598018646240234, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.6274, 'grad_norm': 20.79182243347168, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.4202, 'grad_norm': 26.824331283569336, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.418, 'grad_norm': 23.258697509765625, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:04, 11.74it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 54%|█████▍    | 54/100 [00:05<00:05,  8.96it/s]
{'loss': 1.2097, 'grad_norm': 29.664159774780273, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.4524, 'grad_norm': 30.916818618774414, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.4049, 'grad_norm': 29.418651580810547, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 1.3087, 'grad_norm': 30.295549392700195, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.4486, 'grad_norm': 33.886329650878906, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.5591, 'grad_norm': 32.021968841552734, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 0.7482, 'grad_norm': 20.311363220214844, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 0.3449, 'grad_norm': 62.52190017700195, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 2.2781, 'grad_norm': 35.090755462646484, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.0636, 'grad_norm': 27.16330909729004, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 1.1381, 'grad_norm': 30.558731079101562, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.8082, 'grad_norm': 37.7116813659668, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 1.8181, 'grad_norm': 71.96387481689453, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 3.24211049079895, 'eval_model_preparation_time': 0.0023, 'eval_runtime': 0.0216, 'eval_samples_per_second': 92.769, 'eval_steps_per_second': 46.384, 'epoch': 5.0}
{'loss': 2.8904, 'grad_norm': 76.51725006103516, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 0.876, 'grad_norm': 37.677555084228516, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 1.3156, 'grad_norm': 42.303009033203125, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.7065, 'grad_norm': 30.985063552856445, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 0.3683, 'grad_norm': 36.234886169433594, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}
{'loss': 0.3939, 'grad_norm': 45.61236572265625, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 1.1334, 'grad_norm': 29.04952621459961, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}

 74%|███████▍  | 74/100 [00:07<00:02,  9.77it/s]
{'loss': 0.5626, 'grad_norm': 31.63137435913086, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.6068, 'grad_norm': 35.40879821777344, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 0.8236, 'grad_norm': 22.04109764099121, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 0.3356, 'grad_norm': 17.36041831970215, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 0.4042, 'grad_norm': 25.883708953857422, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 1.7043, 'grad_norm': 26.864805221557617, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.2274, 'grad_norm': 30.84493064880371, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 0.6963, 'grad_norm': 34.27804183959961, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 1.7906, 'grad_norm': 37.9301643371582, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 0.8865, 'grad_norm': 29.688791275024414, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 2.0127, 'grad_norm': 48.34822463989258, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.2962, 'grad_norm': 68.0794448852539, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.8604, 'grad_norm': 24.39195442199707, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 1.9396, 'grad_norm': 31.125080108642578, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 1.4679, 'grad_norm': 42.07356262207031, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.4148, 'grad_norm': 34.61995315551758, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 1.782, 'grad_norm': 37.69855499267578, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.0177, 'grad_norm': 71.17201232910156, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 0.3426, 'grad_norm': 40.592803955078125, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}

 94%|█████████▍| 94/100 [00:09<00:00,  9.76it/s]
{'loss': 0.3111, 'grad_norm': 19.212373733520508, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 1.0169, 'grad_norm': 34.455989837646484, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 0.5345, 'grad_norm': 32.882362365722656, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.6419, 'grad_norm': 47.50642013549805, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.4722, 'grad_norm': 41.57521057128906, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.2289, 'grad_norm': 25.26589012145996, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.6026, 'grad_norm': 30.01906967163086, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 0.9551, 'grad_norm': 51.5229377746582, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 1.3415, 'grad_norm': 41.34392547607422, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 0.6104, 'grad_norm': 38.89051055908203, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 1.7079, 'grad_norm': 25.193588256835938, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.0792, 'grad_norm': 19.91963768005371, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 1.7849, 'grad_norm': 25.118003845214844, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.4352, 'grad_norm': 31.573230743408203, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.2955, 'grad_norm': 24.20081901550293, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.2176, 'grad_norm': 33.187496185302734, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 0.255, 'grad_norm': 19.65089225769043, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.2068, 'grad_norm': 24.96323585510254, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 2.108, 'grad_norm': 40.9909553527832, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
100%|██████████| 100/100 [00:09<00:00,  9.71it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.85it/s]
{'loss': 1.1166, 'grad_norm': 29.54280662536621, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 1.6964, 'grad_norm': 34.7139778137207, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 3.2540438175201416, 'eval_model_preparation_time': 0.0023, 'eval_runtime': 0.0217, 'eval_samples_per_second': 92.196, 'eval_steps_per_second': 46.098, 'epoch': 10.0}
{'train_runtime': 10.153, 'train_samples_per_second': 39.397, 'train_steps_per_second': 9.849, 'train_loss': 1.23581448584795, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 6