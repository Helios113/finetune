/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 935.39it/s]
 12%|█▏        | 12/100 [00:01<00:08, 10.61it/s]
{'loss': 0.9755, 'grad_norm': 10.854288101196289, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.9154, 'grad_norm': 20.764686584472656, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.4739, 'grad_norm': 24.56684684753418, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.994, 'grad_norm': 19.214147567749023, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.1203, 'grad_norm': 17.113832473754883, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 2.349, 'grad_norm': 20.296579360961914, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.817, 'grad_norm': 30.42909049987793, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 3.5753, 'grad_norm': 21.63199806213379, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 3.2051, 'grad_norm': 18.155603408813477, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 3.7658, 'grad_norm': 24.991641998291016, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 0.6168, 'grad_norm': 32.08287048339844, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 2.1321, 'grad_norm': 69.2348861694336, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 1.9016, 'grad_norm': 18.389015197753906, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 3.498, 'grad_norm': 15.843581199645996, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.5247, 'grad_norm': 30.907060623168945, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}
{'loss': 1.7572, 'grad_norm': 13.700223922729492, 'learning_rate': 4.690766700109659e-05, 'epoch': 1.6}

 32%|███▏      | 32/100 [00:03<00:06, 10.06it/s]
{'loss': 2.8116, 'grad_norm': 14.333062171936035, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 3.4018, 'grad_norm': 20.113969802856445, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 1.8856, 'grad_norm': 56.663421630859375, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 2.0446, 'grad_norm': 15.270933151245117, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 2.7287, 'grad_norm': 19.800878524780273, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 3.9573, 'grad_norm': 20.96784210205078, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.3757, 'grad_norm': 15.732973098754883, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.2049, 'grad_norm': 17.67789649963379, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 1.3767, 'grad_norm': 14.824435234069824, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 2.0039, 'grad_norm': 14.447734832763672, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 1.3028, 'grad_norm': 16.201875686645508, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 2.0786, 'grad_norm': 16.074508666992188, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 3.5107, 'grad_norm': 24.200851440429688, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 3.4218, 'grad_norm': 17.977651596069336, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 2.6415, 'grad_norm': 19.282468795776367, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 2.5081, 'grad_norm': 19.78230094909668, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 1.2334, 'grad_norm': 13.32347297668457, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 2.0997, 'grad_norm': 15.768906593322754, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.7736, 'grad_norm': 12.45157527923584, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:04, 10.41it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:06,  7.99it/s]
{'loss': 3.7623, 'grad_norm': 18.68483543395996, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.6572, 'grad_norm': 20.06023406982422, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.6031, 'grad_norm': 54.143436431884766, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 2.3434, 'grad_norm': 20.956430435180664, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.9068, 'grad_norm': 26.363615036010742, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.2212, 'grad_norm': 13.000811576843262, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 2.9019, 'grad_norm': 28.891775131225586, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 3.2189, 'grad_norm': 19.696369171142578, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 0.5638, 'grad_norm': 11.008832931518555, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 1.6217, 'grad_norm': 17.745014190673828, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 2.5717, 'grad_norm': 17.66522979736328, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 2.324, 'grad_norm': 14.899895668029785, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.8285, 'grad_norm': 29.7431583404541, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 1.7297892570495605, 'eval_model_preparation_time': 0.0009, 'eval_runtime': 0.0187, 'eval_samples_per_second': 106.705, 'eval_steps_per_second': 53.352, 'epoch': 5.0}
{'loss': 1.4452, 'grad_norm': 16.68168067932129, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.6771, 'grad_norm': 17.923954010009766, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 1.6232, 'grad_norm': 15.472125053405762, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 2.7828, 'grad_norm': 19.35717010498047, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 2.4229, 'grad_norm': 15.346198081970215, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}

 73%|███████▎  | 73/100 [00:07<00:02, 10.52it/s]
{'loss': 1.9632, 'grad_norm': 13.498076438903809, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 2.3443, 'grad_norm': 34.990936279296875, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.6112, 'grad_norm': 20.864070892333984, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 1.8707, 'grad_norm': 21.030658721923828, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 2.769, 'grad_norm': 19.71245765686035, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 2.5833, 'grad_norm': 19.758737564086914, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 0.4478, 'grad_norm': 13.309170722961426, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 2.3737, 'grad_norm': 21.404705047607422, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.6287, 'grad_norm': 14.253329277038574, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.1285, 'grad_norm': 19.23592758178711, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 3.2462, 'grad_norm': 17.063289642333984, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.9773, 'grad_norm': 17.003437042236328, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 1.2077, 'grad_norm': 16.131715774536133, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.1895, 'grad_norm': 54.395633697509766, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.7287, 'grad_norm': 19.464719772338867, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 2.6082, 'grad_norm': 26.225412368774414, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 2.5228, 'grad_norm': 17.679611206054688, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 2.3914, 'grad_norm': 32.01209259033203, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 0.4885, 'grad_norm': 23.75174331665039, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.8464, 'grad_norm': 17.55432891845703, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.0501, 'grad_norm': 28.705158233642578, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}

 96%|█████████▌| 96/100 [00:09<00:00, 11.00it/s]
{'loss': 0.3956, 'grad_norm': 7.640096187591553, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 1.7526, 'grad_norm': 22.09493637084961, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.0593, 'grad_norm': 14.731159210205078, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 2.0324, 'grad_norm': 26.654582977294922, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 0.8395, 'grad_norm': 11.009879112243652, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 0.75, 'grad_norm': 28.647607803344727, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 2.8644, 'grad_norm': 15.477519989013672, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 2.5852, 'grad_norm': 24.5189266204834, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 1.1748, 'grad_norm': 17.401397705078125, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 3.2973, 'grad_norm': 24.240123748779297, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.9111, 'grad_norm': 21.41209602355957, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 1.0617, 'grad_norm': 20.29384422302246, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 2.5142, 'grad_norm': 18.739547729492188, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 1.6768, 'grad_norm': 17.794681549072266, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 1.3399, 'grad_norm': 16.098108291625977, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 2.0948, 'grad_norm': 25.659177780151367, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 3.1711, 'grad_norm': 24.30214500427246, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.1372, 'grad_norm': 25.24747085571289, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 2.9319, 'grad_norm': 23.12677574157715, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.8399, 'grad_norm': 13.972761154174805, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 1.6374, 'grad_norm': 22.168460845947266, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 0.2291, 'grad_norm': 22.251731872558594, 'learning_rate': 0.0, 'epoch': 10.0}
100%|██████████| 100/100 [00:09<00:00, 10.37it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:09<00:00, 10.08it/s]
{'train_runtime': 9.9148, 'train_samples_per_second': 40.344, 'train_steps_per_second': 10.086, 'train_loss': 2.039670792520046, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 1