/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 1473.75it/s]
 12%|█▏        | 12/100 [00:01<00:08, 10.28it/s]
{'loss': 0.8834, 'grad_norm': 42.32545852661133, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 2.123, 'grad_norm': 43.557716369628906, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.763, 'grad_norm': 25.00251579284668, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 1.8202, 'grad_norm': 45.824100494384766, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.4758, 'grad_norm': 35.24435806274414, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 2.8517, 'grad_norm': 21.395137786865234, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 1.0575, 'grad_norm': 27.37560272216797, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.1824, 'grad_norm': 25.231521606445312, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 2.3957, 'grad_norm': 53.46876907348633, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 2.3918, 'grad_norm': 21.13413429260254, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.8152, 'grad_norm': 40.65535354614258, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 1.0996, 'grad_norm': 111.96062469482422, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.8456, 'grad_norm': 29.40808868408203, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.9815, 'grad_norm': 21.871715545654297, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 2.2101, 'grad_norm': 27.321855545043945, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:06, 10.00it/s]
{'loss': 2.4931, 'grad_norm': 25.272489547729492, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.065, 'grad_norm': 16.92573356628418, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.5982, 'grad_norm': 25.061796188354492, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 0.902, 'grad_norm': 22.246013641357422, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 1.4637, 'grad_norm': 28.01947784423828, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 3.1747, 'grad_norm': 30.88196563720703, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 1.9143, 'grad_norm': 47.89019012451172, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 1.1219, 'grad_norm': 23.236774444580078, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 0.731, 'grad_norm': 46.90684509277344, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 2.5638, 'grad_norm': 26.72283935546875, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 2.6426, 'grad_norm': 21.746143341064453, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 0.8581, 'grad_norm': 30.260395050048828, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 1.9243, 'grad_norm': 58.783695220947266, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 2.3562, 'grad_norm': 31.1046199798584, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 0.9672, 'grad_norm': 29.66961669921875, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 2.4584, 'grad_norm': 20.330280303955078, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 2.1523, 'grad_norm': 42.435611724853516, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 1.7435, 'grad_norm': 23.990402221679688, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 1.6254, 'grad_norm': 16.800846099853516, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}

 50%|█████     | 50/100 [00:05<00:05,  9.83it/s]
{'loss': 2.2279, 'grad_norm': 32.29855728149414, 'learning_rate': 3.4928697265869515e-05, 'epoch': 3.7}
{'loss': 1.5087, 'grad_norm': 16.33263397216797, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 2.6563, 'grad_norm': 28.788259506225586, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 1.085, 'grad_norm': 30.7299747467041, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 1.0272, 'grad_norm': 23.07638168334961, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 0.8035, 'grad_norm': 29.301799774169922, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 1.8082, 'grad_norm': 21.536457061767578, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 0.8606, 'grad_norm': 19.5902042388916, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 3.2074, 'grad_norm': 22.510618209838867, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 3.263, 'grad_norm': 33.82741928100586, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 2.0341, 'grad_norm': 30.451663970947266, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 0.948, 'grad_norm': 51.27853775024414, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 1.2133, 'grad_norm': 15.972862243652344, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.3658, 'grad_norm': 70.54004669189453, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.8285432457923889, 'eval_model_preparation_time': 0.0015, 'eval_runtime': 0.0218, 'eval_samples_per_second': 91.79, 'eval_steps_per_second': 45.895, 'epoch': 5.0}
{'loss': 1.5255, 'grad_norm': 30.096357345581055, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 0.7666, 'grad_norm': 38.36286926269531, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 2.4669, 'grad_norm': 26.292556762695312, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.3394, 'grad_norm': 37.128963470458984, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
 50%|█████     | 50/100 [00:05<00:05,  9.83it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 71%|███████   | 71/100 [00:07<00:02,  9.88it/s]
{'loss': 1.4779, 'grad_norm': 19.05060386657715, 'learning_rate': 2.031546713535688e-05, 'epoch': 5.6}
{'loss': 0.9933, 'grad_norm': 21.653505325317383, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 2.9559, 'grad_norm': 23.4113712310791, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 2.1134, 'grad_norm': 27.73969078063965, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 0.5463, 'grad_norm': 27.718204498291016, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.4336, 'grad_norm': 34.50627136230469, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 2.3369, 'grad_norm': 65.23985290527344, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 2.5808, 'grad_norm': 21.11014747619629, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 0.4441, 'grad_norm': 16.108518600463867, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 0.7352, 'grad_norm': 27.090105056762695, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 2.1153, 'grad_norm': 38.89456558227539, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 2.4874, 'grad_norm': 46.40153121948242, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 0.772, 'grad_norm': 21.31393814086914, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 2.2928, 'grad_norm': 21.92674446105957, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 0.9647, 'grad_norm': 59.33913040161133, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 1.7991, 'grad_norm': 91.37358093261719, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 0.6449, 'grad_norm': 18.032188415527344, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 2.6119, 'grad_norm': 38.261653900146484, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.2721, 'grad_norm': 19.951627731323242, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}

 92%|█████████▏| 92/100 [00:09<00:00, 10.20it/s]
{'loss': 1.3312, 'grad_norm': 45.73905944824219, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}
{'loss': 1.9041, 'grad_norm': 34.97886657714844, 'learning_rate': 6.247223259238511e-06, 'epoch': 7.7}
{'loss': 1.6148, 'grad_norm': 39.21293258666992, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 1.6521, 'grad_norm': 31.55869483947754, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.6164, 'grad_norm': 60.12112045288086, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.2856, 'grad_norm': 37.667762756347656, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.7921, 'grad_norm': 58.49829864501953, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 2.3135, 'grad_norm': 36.743106842041016, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 0.9319, 'grad_norm': 22.135623931884766, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.2103, 'grad_norm': 30.69220542907715, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.9063, 'grad_norm': 20.7852725982666, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 2.2056, 'grad_norm': 89.06157684326172, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 1.9715, 'grad_norm': 60.78359603881836, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 1.7991, 'grad_norm': 28.122509002685547, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 0.4053, 'grad_norm': 58.01948165893555, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 0.8017, 'grad_norm': 20.02800941467285, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 0.5655, 'grad_norm': 52.420841217041016, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 1.1155, 'grad_norm': 44.442562103271484, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 1.4007, 'grad_norm': 17.610275268554688, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 1.7807, 'grad_norm': 38.504966735839844, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
100%|██████████| 100/100 [00:10<00:00,  9.86it/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.66it/s]
{'loss': 2.6901, 'grad_norm': 60.23617935180664, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
{'loss': 1.435, 'grad_norm': 26.05159568786621, 'learning_rate': 4.9331789293211026e-08, 'epoch': 9.8}
{'loss': 2.2626, 'grad_norm': 31.35908317565918, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 2.8804, 'grad_norm': 48.72578430175781, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.8323299288749695, 'eval_model_preparation_time': 0.0015, 'eval_runtime': 0.0208, 'eval_samples_per_second': 96.202, 'eval_steps_per_second': 48.101, 'epoch': 10.0}
{'train_runtime': 10.3437, 'train_samples_per_second': 38.671, 'train_steps_per_second': 9.668, 'train_loss': 1.7634063681960106, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 8