/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.
  obj.co_lnotab,  # for < python 3.10 [not counted in args]
Map: 100%|██████████| 38/38 [00:00<00:00, 1165.59 examples/s]
Map: 100%|██████████| 2/2 [00:00<00:00, 113.26 examples/s]
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSFTTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs
100%|██████████| 1/1 [00:00<00:00, 1321.87it/s]
 11%|█         | 11/100 [00:01<00:08, 10.06it/s]
{'loss': 1.4276, 'grad_norm': 22.47382164001465, 'learning_rate': 4.998766400914329e-05, 'epoch': 0.1}
{'loss': 1.9158, 'grad_norm': 20.425600051879883, 'learning_rate': 4.995066821070679e-05, 'epoch': 0.2}
{'loss': 2.666, 'grad_norm': 24.659202575683594, 'learning_rate': 4.9889049115077005e-05, 'epoch': 0.3}
{'loss': 2.4806, 'grad_norm': 13.234495162963867, 'learning_rate': 4.980286753286195e-05, 'epoch': 0.4}
{'loss': 2.9315, 'grad_norm': 22.432300567626953, 'learning_rate': 4.9692208514878444e-05, 'epoch': 0.5}
{'loss': 0.8266, 'grad_norm': 17.059967041015625, 'learning_rate': 4.9557181268217227e-05, 'epoch': 0.6}
{'loss': 2.779, 'grad_norm': 19.483999252319336, 'learning_rate': 4.939791904846869e-05, 'epoch': 0.7}
{'loss': 2.7122, 'grad_norm': 17.609577178955078, 'learning_rate': 4.9214579028215776e-05, 'epoch': 0.8}
{'loss': 1.3849, 'grad_norm': 22.128202438354492, 'learning_rate': 4.900734214192358e-05, 'epoch': 0.9}
{'loss': 0.8619, 'grad_norm': 33.422645568847656, 'learning_rate': 4.877641290737884e-05, 'epoch': 1.0}
{'loss': 1.9975, 'grad_norm': 26.823244094848633, 'learning_rate': 4.852201922385564e-05, 'epoch': 1.1}
{'loss': 0.8122, 'grad_norm': 21.604158401489258, 'learning_rate': 4.8244412147206284e-05, 'epoch': 1.2}
{'loss': 2.7724, 'grad_norm': 38.77574920654297, 'learning_rate': 4.794386564209953e-05, 'epoch': 1.3}
{'loss': 2.2736, 'grad_norm': 27.800954818725586, 'learning_rate': 4.762067631165049e-05, 'epoch': 1.4}
{'loss': 1.9432, 'grad_norm': 19.75769805908203, 'learning_rate': 4.72751631047092e-05, 'epoch': 1.5}

 32%|███▏      | 32/100 [00:03<00:06, 10.19it/s]
{'loss': 1.8921, 'grad_norm': 28.436443328857422, 'learning_rate': 4.65185506750986e-05, 'epoch': 1.7}
{'loss': 1.8606, 'grad_norm': 24.32091522216797, 'learning_rate': 4.610819813755038e-05, 'epoch': 1.8}
{'loss': 2.7621, 'grad_norm': 27.697952270507812, 'learning_rate': 4.567701435686404e-05, 'epoch': 1.9}
{'loss': 1.2929, 'grad_norm': 36.995750427246094, 'learning_rate': 4.522542485937369e-05, 'epoch': 2.0}
{'loss': 1.7015, 'grad_norm': 28.897550582885742, 'learning_rate': 4.4753875309392266e-05, 'epoch': 2.1}
{'loss': 3.0016, 'grad_norm': 26.753952026367188, 'learning_rate': 4.426283106939474e-05, 'epoch': 2.2}
{'loss': 2.8951, 'grad_norm': 28.535825729370117, 'learning_rate': 4.375277674076149e-05, 'epoch': 2.3}
{'loss': 2.08, 'grad_norm': 16.852739334106445, 'learning_rate': 4.3224215685535294e-05, 'epoch': 2.4}
{'loss': 1.7246, 'grad_norm': 18.46074867248535, 'learning_rate': 4.267766952966369e-05, 'epoch': 2.5}
{'loss': 2.1062, 'grad_norm': 21.431819915771484, 'learning_rate': 4.211367764821722e-05, 'epoch': 2.6}
{'loss': 1.2052, 'grad_norm': 18.08995819091797, 'learning_rate': 4.1532796633091296e-05, 'epoch': 2.7}
{'loss': 1.3285, 'grad_norm': 19.371257781982422, 'learning_rate': 4.093559974371725e-05, 'epoch': 2.8}
{'loss': 1.397, 'grad_norm': 25.283231735229492, 'learning_rate': 4.0322676341324415e-05, 'epoch': 2.9}
{'loss': 0.6326, 'grad_norm': 18.16733169555664, 'learning_rate': 3.969463130731183e-05, 'epoch': 3.0}
{'loss': 1.8229, 'grad_norm': 21.49077033996582, 'learning_rate': 3.905208444630327e-05, 'epoch': 3.1}
{'loss': 1.6766, 'grad_norm': 35.38127517700195, 'learning_rate': 3.8395669874474915e-05, 'epoch': 3.2}
{'loss': 1.3377, 'grad_norm': 18.522377014160156, 'learning_rate': 3.7726035393759285e-05, 'epoch': 3.3}
{'loss': 0.635, 'grad_norm': 10.557625770568848, 'learning_rate': 3.704384185254288e-05, 'epoch': 3.4}
{'loss': 2.0304, 'grad_norm': 13.58725643157959, 'learning_rate': 3.634976249348867e-05, 'epoch': 3.5}
{'loss': 0.9156, 'grad_norm': 16.87694549560547, 'learning_rate': 3.564448228912682e-05, 'epoch': 3.6}
 50%|█████     | 50/100 [00:04<00:04, 10.36it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
 51%|█████     | 51/100 [00:05<00:05,  8.65it/s]
{'loss': 3.2294, 'grad_norm': 17.566844940185547, 'learning_rate': 3.4203113817116957e-05, 'epoch': 3.8}
{'loss': 1.3987, 'grad_norm': 53.91686248779297, 'learning_rate': 3.346844800613229e-05, 'epoch': 3.9}
{'loss': 0.5984, 'grad_norm': 14.254332542419434, 'learning_rate': 3.272542485937369e-05, 'epoch': 4.0}
{'loss': 2.4683, 'grad_norm': 25.14262580871582, 'learning_rate': 3.1974777650980735e-05, 'epoch': 4.1}
{'loss': 1.7405, 'grad_norm': 37.90181350708008, 'learning_rate': 3.121724717912138e-05, 'epoch': 4.2}
{'loss': 3.3139, 'grad_norm': 64.66714477539062, 'learning_rate': 3.045358103491357e-05, 'epoch': 4.3}
{'loss': 0.9605, 'grad_norm': 15.356698989868164, 'learning_rate': 2.9684532864643122e-05, 'epoch': 4.4}
{'loss': 1.3134, 'grad_norm': 21.352628707885742, 'learning_rate': 2.8910861626005776e-05, 'epoch': 4.5}
{'loss': 2.2691, 'grad_norm': 31.482816696166992, 'learning_rate': 2.8133330839107608e-05, 'epoch': 4.6}
{'loss': 0.622, 'grad_norm': 11.230713844299316, 'learning_rate': 2.7352707832962865e-05, 'epoch': 4.7}
{'loss': 1.7627, 'grad_norm': 22.079395294189453, 'learning_rate': 2.656976298823284e-05, 'epoch': 4.8}
{'loss': 0.6825, 'grad_norm': 18.812047958374023, 'learning_rate': 2.578526897695321e-05, 'epoch': 4.9}
{'loss': 2.7198, 'grad_norm': 27.397274017333984, 'learning_rate': 2.5e-05, 'epoch': 5.0}
{'eval_loss': 0.6345905661582947, 'eval_model_preparation_time': 0.001, 'eval_runtime': 0.0148, 'eval_samples_per_second': 134.913, 'eval_steps_per_second': 67.456, 'epoch': 5.0}
{'loss': 2.902, 'grad_norm': 30.59925651550293, 'learning_rate': 2.4214731023046793e-05, 'epoch': 5.1}
{'loss': 1.5301, 'grad_norm': 12.818388938903809, 'learning_rate': 2.3430237011767167e-05, 'epoch': 5.2}
{'loss': 2.3343, 'grad_norm': 14.92374038696289, 'learning_rate': 2.2647292167037144e-05, 'epoch': 5.3}
{'loss': 1.9541, 'grad_norm': 22.904531478881836, 'learning_rate': 2.186666916089239e-05, 'epoch': 5.4}
{'loss': 1.2366, 'grad_norm': 20.804977416992188, 'learning_rate': 2.1089138373994223e-05, 'epoch': 5.5}

 72%|███████▏  | 72/100 [00:07<00:02, 10.21it/s]
{'loss': 0.6052, 'grad_norm': 12.348556518554688, 'learning_rate': 1.9546418965086442e-05, 'epoch': 5.7}
{'loss': 2.4483, 'grad_norm': 27.518037796020508, 'learning_rate': 1.8782752820878634e-05, 'epoch': 5.8}
{'loss': 0.8974, 'grad_norm': 20.120403289794922, 'learning_rate': 1.802522234901927e-05, 'epoch': 5.9}
{'loss': 2.3879, 'grad_norm': 24.984533309936523, 'learning_rate': 1.7274575140626318e-05, 'epoch': 6.0}
{'loss': 1.6211, 'grad_norm': 15.313676834106445, 'learning_rate': 1.6531551993867717e-05, 'epoch': 6.1}
{'loss': 0.5272, 'grad_norm': 17.574195861816406, 'learning_rate': 1.5796886182883053e-05, 'epoch': 6.2}
{'loss': 1.862, 'grad_norm': 20.312227249145508, 'learning_rate': 1.5071302734130489e-05, 'epoch': 6.3}
{'loss': 2.4251, 'grad_norm': 21.0739688873291, 'learning_rate': 1.4355517710873184e-05, 'epoch': 6.4}
{'loss': 1.5804, 'grad_norm': 11.456531524658203, 'learning_rate': 1.3650237506511331e-05, 'epoch': 6.5}
{'loss': 1.3877, 'grad_norm': 14.256299018859863, 'learning_rate': 1.2956158147457115e-05, 'epoch': 6.6}
{'loss': 1.9742, 'grad_norm': 24.260499954223633, 'learning_rate': 1.2273964606240718e-05, 'epoch': 6.7}
{'loss': 1.6106, 'grad_norm': 28.50348472595215, 'learning_rate': 1.1604330125525079e-05, 'epoch': 6.8}
{'loss': 1.8237, 'grad_norm': 44.806758880615234, 'learning_rate': 1.0947915553696742e-05, 'epoch': 6.9}
{'loss': 2.9213, 'grad_norm': 49.69801330566406, 'learning_rate': 1.0305368692688174e-05, 'epoch': 7.0}
{'loss': 2.0355, 'grad_norm': 41.90851593017578, 'learning_rate': 9.677323658675594e-06, 'epoch': 7.1}
{'loss': 3.0252, 'grad_norm': 18.312889099121094, 'learning_rate': 9.064400256282757e-06, 'epoch': 7.2}
{'loss': 0.9552, 'grad_norm': 18.39019012451172, 'learning_rate': 8.467203366908707e-06, 'epoch': 7.3}
{'loss': 1.6395, 'grad_norm': 25.952821731567383, 'learning_rate': 7.886322351782783e-06, 'epoch': 7.4}
{'loss': 2.0292, 'grad_norm': 36.8001823425293, 'learning_rate': 7.3223304703363135e-06, 'epoch': 7.5}
{'loss': 1.8985, 'grad_norm': 19.574026107788086, 'learning_rate': 6.775784314464717e-06, 'epoch': 7.6}

 93%|█████████▎| 93/100 [00:09<00:00, 10.15it/s]
{'loss': 0.7258, 'grad_norm': 24.704959869384766, 'learning_rate': 5.737168930605272e-06, 'epoch': 7.8}
{'loss': 0.9178, 'grad_norm': 20.592300415039062, 'learning_rate': 5.24612469060774e-06, 'epoch': 7.9}
{'loss': 2.9416, 'grad_norm': 62.34098434448242, 'learning_rate': 4.7745751406263165e-06, 'epoch': 8.0}
{'loss': 1.6063, 'grad_norm': 25.76050567626953, 'learning_rate': 4.322985643135952e-06, 'epoch': 8.1}
{'loss': 1.8624, 'grad_norm': 17.124338150024414, 'learning_rate': 3.891801862449629e-06, 'epoch': 8.2}
{'loss': 1.6561, 'grad_norm': 17.57003402709961, 'learning_rate': 3.4814493249014116e-06, 'epoch': 8.3}
{'loss': 1.5806, 'grad_norm': 37.04738235473633, 'learning_rate': 3.092332998903416e-06, 'epoch': 8.4}
{'loss': 1.5486, 'grad_norm': 17.806299209594727, 'learning_rate': 2.7248368952908053e-06, 'epoch': 8.5}
{'loss': 1.9827, 'grad_norm': 19.893796920776367, 'learning_rate': 2.379323688349516e-06, 'epoch': 8.6}
{'loss': 1.4481, 'grad_norm': 27.5131778717041, 'learning_rate': 2.0561343579004715e-06, 'epoch': 8.7}
{'loss': 1.4812, 'grad_norm': 29.036663055419922, 'learning_rate': 1.7555878527937164e-06, 'epoch': 8.8}
{'loss': 2.7424, 'grad_norm': 28.305288314819336, 'learning_rate': 1.4779807761443636e-06, 'epoch': 8.9}
{'loss': 1.1154, 'grad_norm': 35.646297454833984, 'learning_rate': 1.2235870926211619e-06, 'epoch': 9.0}
{'loss': 2.0036, 'grad_norm': 30.662391662597656, 'learning_rate': 9.926578580764234e-07, 'epoch': 9.1}
{'loss': 1.677, 'grad_norm': 16.146860122680664, 'learning_rate': 7.854209717842231e-07, 'epoch': 9.2}
{'loss': 0.7471, 'grad_norm': 16.708187103271484, 'learning_rate': 6.020809515313142e-07, 'epoch': 9.3}
{'loss': 2.2337, 'grad_norm': 21.864213943481445, 'learning_rate': 4.4281873178278475e-07, 'epoch': 9.4}
{'loss': 0.5422, 'grad_norm': 13.27727222442627, 'learning_rate': 3.077914851215585e-07, 'epoch': 9.5}
{'loss': 1.7332, 'grad_norm': 19.49034309387207, 'learning_rate': 1.9713246713805588e-07, 'epoch': 9.6}
{'loss': 2.5588, 'grad_norm': 17.076637268066406, 'learning_rate': 1.109508849230001e-07, 'epoch': 9.7}
100%|██████████| 100/100 [00:09<00:00, 10.05it//nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
100%|██████████| 100/100 [00:10<00:00,  9.85it/s]
{'loss': 2.0619, 'grad_norm': 18.133785247802734, 'learning_rate': 1.233599085671e-08, 'epoch': 9.9}
{'loss': 1.6463, 'grad_norm': 19.728260040283203, 'learning_rate': 0.0, 'epoch': 10.0}
{'eval_loss': 0.6656176447868347, 'eval_model_preparation_time': 0.001, 'eval_runtime': 0.0202, 'eval_samples_per_second': 99.234, 'eval_steps_per_second': 49.617, 'epoch': 10.0}
{'train_runtime': 10.1553, 'train_samples_per_second': 39.388, 'train_steps_per_second': 9.847, 'train_loss': 1.7965421974658966, 'epoch': 10.0}
/nfs-share/pa511/.cache/pypoetry/virtualenvs/llm-memorization1-iHoaSaFW-py3.12/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:174: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
  self.FromDatetime(datetime.datetime.utcnow())
Client id: 2